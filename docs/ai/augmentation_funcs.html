<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.1" />
<title>buteo.ai.augmentation_funcs API documentation</title>
<meta name="description" content="This module contains functions for augmenting images that are
suited to remote sensing imagery." />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>buteo.ai.augmentation_funcs</code></h1>
</header>
<section id="section-intro">
<p>This module contains functions for augmenting images that are
suited to remote sensing imagery.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
This module contains functions for augmenting images that are
suited to remote sensing imagery.
&#34;&#34;&#34;
# Standard library
import sys; sys.path.append(&#34;../../&#34;)
from typing import Optional, Tuple, Any

# External
import numpy as np
from numba import jit, prange

# Internal
from buteo.ai.augmentation_utils import (
    fit_data_to_dtype,
    feather_box_2d,
    rotate_arr,
    mirror_arr,
    simple_blur_kernel_2d_3x3,
    simple_unsharp_kernel_2d_3x3,
    simple_shift_kernel_2d,
    convolution_simple,
)


@jit(nopython=True, nogil=True, cache=True, fastmath=True)
def augmentation_rotation(
    X: np.ndarray,
    y: Optional[np.ndarray],
    chance: float = 0.5,
    k: Optional[int] = None,
    channel_last: bool = True,
) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:
    &#34;&#34;&#34;
    Randomly rotate the image by 90 degrees intervals. Images
    can be (channels, height, width) or (height, width, channels).

    Args:
        X (np.ndarray): The image to rotate.
        y (np.ndarray/None): The label to rotate.

    Keyword Args:
        chance (float=0.5): The chance of rotating the image.
        k (int=None): The number of 90 degree intervals to rotate by.
        channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).

    Returns:
        Tuple[np.ndarray, Optional[np.ndarray]]: The rotated image and optionally the label.
    &#34;&#34;&#34;
    if np.random.rand() &gt; chance or k == 0:
        return X, y

    random_k = np.random.randint(1, 4) if k is None else k
    X_rot = rotate_arr(X, random_k, channel_last)

    if y is None:
        return X_rot, y

    y_rot = rotate_arr(y, random_k, channel_last)

    return X_rot, y_rot


@jit(nopython=True, nogil=True, cache=True, fastmath=True)
def augmentation_mirror(
    X: np.ndarray,
    y: Optional[np.ndarray],
    chance: float = 0.5,
    k: Optional[int] = None,
    channel_last: bool = True,
) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:
    &#34;&#34;&#34;
    Randomly mirrors the image. Images can be (channels, height, width) or (height, width, channels).

    Args:
        X (np.ndarray): The image to mirror.
        y (np.ndarray/None): The label to mirror.

    Keyword Args:
        chance (float=0.5): The chance of mirroring the image.
        k (int=None): If None, randomly mirrors the image along the horizontal or vertical axis.
            If 1, mirrors the image along the horizontal axis.
            If 2, mirrors the image along the vertical axis.
            If 3, mirrors the image along both the horizontal and vertical axis.
        channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).

    Returns:
        Tuple[np.ndarray, Optional[np.ndarray]]: The mirrored image and optionally the label.
    &#34;&#34;&#34;
    if np.random.rand() &gt; chance or k == 0:
        return X, y

    random_k = np.random.randint(1, 4) if k is None else k

    flipped_x = mirror_arr(X, random_k, channel_last)
    flipped_y = mirror_arr(y, random_k, channel_last) if y is not None else None

    return flipped_x, flipped_y


@jit(nopython=True, nogil=True, cache=True, fastmath=True)
def augmentation_noise(
    X: np.ndarray,
    y: Optional[np.ndarray],
    chance: float = 0.5,
    max_amount: float = 0.1,
    additive: bool = False,
    channel_last: Any = None, # pylint: disable=unused-argument
) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:
    &#34;&#34;&#34;
    Adds random noise seperately to each pixel of the image. The noise works
    for both channel first and last images.
    input should be (height, width, channels) or (channels, height, width).

    Args:
        X (np.ndarray): The image to add noise to.
        y (np.ndarray/None): The label to add noise to. If None, no label is returned.

    Keyword Args:
        chance (float=0.5): The chance of adding noise.
        max_amount (float=0.1): The maximum amount of noise to add, sampled uniformly.
        additive (bool=False): Whether to add or multiply the noise.
        channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).
            ignored for this function. Kept to keep the same function signature as other augmentations.

    Returns:
        Tuple[np.ndarray, Optional[np.ndarray]]: The image with noise and optionally the unmodified label.
    &#34;&#34;&#34;
    if np.random.rand() &gt; chance:
        return X, y

    amount = np.random.rand() * max_amount

    if additive:
        noisy_x = X + np.random.normal(0, amount, X.shape)
    else:
        noisy_x = X * np.random.normal(1, amount, X.shape)

    return fit_data_to_dtype(noisy_x, X.dtype), y


@jit(nopython=True, nogil=True, cache=True, fastmath=True, parallel=True)
def augmentation_channel_scale(
    X: np.ndarray,
    y: Optional[np.ndarray],
    chance: float = 0.5,
    max_amount: float = 0.1,
    additive: bool = False,
    channel_last: bool = True,
) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:
    &#34;&#34;&#34;
    Scales the channels of the image seperately by a fixed amount.
    input should be (height, width, channels) or (channels, height, width).

    Args:
        X (np.ndarray): The image to scale the channels of.
        y (np.ndarray/None): The label to scale the channels of. If None, no label is returned.

    Keyword Args:
        chance (float=0.5): The chance of scaling the channels.
        max_amount (float=0.1): The amount to possible scale the channels by. Sampled uniformly.
        additive (bool=False): Whether to add or multiply the scaling.
        channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).

    Returns:
        Tuple[np.ndarray, Optional[np.ndarray]]: The image with scaled channels and optionally the unmodified label.
    &#34;&#34;&#34;
    if np.random.rand() &gt; chance:
        return X, y

    x_scaled = X.astype(np.float32)
    y_scaled = y

    amount = np.random.rand() * max_amount

    if channel_last:
        for i in prange(X.shape[2]):
            if additive:
                random_amount = np.random.uniform(-amount, amount)
                x_scaled[:, :, i] += random_amount
            else:
                random_amount = np.random.uniform(1 - amount, 1 + amount)
                x_scaled[:, :, i] *= random_amount
    else:
        for i in prange(X.shape[0]):
            if additive:
                random_amount = np.random.uniform(-amount, amount)
                x_scaled[i, :, :] += random_amount
            else:
                random_amount = np.random.uniform(1 - amount, 1 + amount)
                x_scaled[i, :, :] *= random_amount

    return fit_data_to_dtype(x_scaled, X.dtype), y_scaled


@jit(nopython=True, nogil=True, cache=True, fastmath=True, parallel=True)
def augmentation_contrast(
    X: np.ndarray,
    y: Optional[np.ndarray],
    chance: float = 0.5,
    max_amount: float = 0.1,
    channel_last: bool = True,
) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:
    &#34;&#34;&#34;
    Changes the contrast of an image by a random amount, seperately for each channel.
    input should be (height, width, channels) or (channels, height, width).

    Args:
        X (np.ndarray): The image to change the contrast of.
        y (np.ndarray/None): The label to change the contrast of. If None, no label is returned.

    Keyword Args:
        chance (float=0.5): The chance of changing the contrast.
        max_amount (float=0.1): The max amount to change the contrast by.
        channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).

    Returns:
        Tuple[np.ndarray, Optional[np.ndarray]]: The image with changed contrast and optionally the unmodified label.
    &#34;&#34;&#34;
    if np.random.rand() &gt; chance:
        return X, y

    x_contrast = X.astype(np.float32)
    y_contrast = y

    amount = np.random.rand() * max_amount

    channels = X.shape[2] if channel_last else X.shape[0]
    mean_pixel = np.array([0.0] * channels, dtype=np.float32)

    # Numba workaround
    if channel_last:
        for i in prange(channels):
            mean_pixel[i] = np.mean(x_contrast[:, :, i])
    else:
        for i in prange(channels):
            mean_pixel[i] = np.mean(x_contrast[i])

    for i in prange(channels):
        x_contrast[:, :, i] = (x_contrast[:, :, i] - mean_pixel[i]) * (1 + amount) + mean_pixel[i]

    return fit_data_to_dtype(x_contrast, X.dtype), y_contrast


@jit(nopython=True, nogil=True, cache=True, fastmath=True, parallel=True)
def augmentation_drop_pixel(
    X: np.ndarray,
    y: Optional[np.ndarray],
    chance: float = 0.5,
    drop_probability: float = 0.01,
    drop_value: float = 0.0,
    channel_last: bool = True,
) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:
    &#34;&#34;&#34;
    Drops a random pixels from an image.
    input should be (height, width, channels) or (channels, height, width).
    Only drops pixels from features, not labels.

    Args:
        X (np.ndarray): The image to drop a pixel from.
        y (np.ndarray/None): The label to drop a pixel from. If None, no label is returned.

    Keyword Args:
        chance (float=0.5): The chance of dropping a pixel.
        drop_probability (float=0.05): The probability of dropping a pixel.
        drop_value (float=0.0): The value to drop the pixel to.
        apply_to_y (bool=False): Whether to apply the drop to the label.
        channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).

    Returns:
        Tuple[np.ndarray, Optional[np.ndarray]]: The image with the dropped pixels and optionally the unmodified label.
    &#34;&#34;&#34;
    if np.random.rand() &gt; chance:
        return X, y

    x_dropped = X.copy()
    y_dropped = y

    mask = np.random.random(size=x_dropped.shape)

    # Agreed. This looks terrible. But it&#39;s the only way to get numba to parallelize this.
    if channel_last:
        for col in prange(X.shape[0]):
            for row in prange(X.shape[1]):
                for channel in prange(X.shape[2]):
                    if mask[col, row, channel] &lt;= drop_probability:
                        x_dropped[col, row, channel] = drop_value

    else:
        for channel in prange(X.shape[0]):
            for col in prange(X.shape[1]):
                for row in prange(X.shape[2]):
                    if mask[channel, col, row] &lt;= drop_probability:
                        x_dropped[channel, col, row] = drop_value

    return x_dropped, y_dropped


@jit(nopython=True, nogil=True, cache=True, fastmath=True)
def augmentation_drop_channel(
    X: np.ndarray,
    y: Optional[np.ndarray],
    chance: float = 0.5,
    drop_probability: float = 0.1,
    drop_value: float = 0.0,
    channel_last: bool = True,
) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:
    &#34;&#34;&#34;
    Drops a random channel from an image.
    input should be (height, width, channels) or (channels, height, width).
    A maximum of one channel will be dropped.

    Args:
        X (np.ndarray): The image to drop a channel from.
        y (np.ndarray/None): The label to drop a channel from. If None, no label is returned.

    Keyword Args:
        chance (float=0.5): The chance of dropping a channel.
        drop_probability (float=0.1): The probability of dropping a channel.
        drop_value (float=0.0): The value to drop the channel to.
        channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).
    &#34;&#34;&#34;
    if np.random.rand() &gt; chance:
        return X, y

    x_dropped = X.copy()
    y_dropped = y

    channels = X.shape[2] if channel_last else X.shape[0]

    drop_a_channel = False
    for _ in range(channels):
        if np.random.rand() &lt; drop_probability:
            drop_a_channel = True
            break

    if not drop_a_channel:
        return X, y

    channel_to_drop = np.random.randint(0, channels)

    if channel_last:
        x_dropped[:, :, channel_to_drop] = drop_value
    else:
        x_dropped[channel_to_drop, :, :] = drop_value

    return x_dropped, y_dropped


@jit(nopython=True, nogil=True, cache=True, fastmath=True, parallel=True)
def augmentation_blur(
    X: np.ndarray,
    y: Optional[np.ndarray],
    chance: float = 0.5,
    intensity: float = 1.0,
    apply_to_y: bool = False,
    channel_last: bool = True,
) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:
    &#34;&#34;&#34;
    Blurs an image at random.
    input should be (height, width, channels) or (channels, height, width).
    Same goes for the label if apply_to_y is True.

    Args:
        X (np.ndarray): The image to potentially blur.
        y (np.ndarray/None): The label to potentially blur. If None, no label is returned.

    Keyword Args:
        chance (float=0.5): The chance of blurring a pixel.
        intensity (float=1.0): The intensity of the blur. from 0.0 to 1.0.
        apply_to_y (bool=False): Whether to blur the label as well.
        channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).
    &#34;&#34;&#34;
    if np.random.rand() &gt; chance:
        return X, y

    x_blurred = X.astype(np.float32)
    y_blurred = y.astype(np.float32) if y is not None else None

    offsets, weights = simple_blur_kernel_2d_3x3()
    channels = X.shape[2] if channel_last else X.shape[0]

    if channel_last:
        for channel in prange(channels):
            x_blurred[:, :, channel] = convolution_simple(x_blurred[:, :, channel], offsets, weights, intensity)
            if apply_to_y and y is not None:
                y_blurred[:, :, channel] = convolution_simple(y_blurred[:, :, channel], offsets, weights, intensity)
    else:
        for channel in prange(channels):
            x_blurred[channel, :, :] = convolution_simple(x_blurred[channel, :, :], offsets, weights, intensity)
            if apply_to_y and y is not None:
                y_blurred[channel, :, :] = convolution_simple(y_blurred[channel, :, :], offsets, weights, intensity)

    x_blurred = fit_data_to_dtype(x_blurred, X.dtype)
    y_blurred = fit_data_to_dtype(y_blurred, y.dtype) if y is not None else None

    return x_blurred, y_blurred


@jit(nopython=True, nogil=True, cache=True, fastmath=True, parallel=True)
def augmentation_sharpen(
    X: np.ndarray,
    y: Optional[np.ndarray],
    chance: float = 0.5,
    intensity: float = 1.0,
    apply_to_y: bool = False,
    channel_last: bool = True,
) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:
    &#34;&#34;&#34;
    Sharpens an image at random.
    input should be (height, width, channels) or (channels, height, width).

    Args:
        X (np.ndarray): The image to potentially sharpen.
        y (np.ndarray/None): The label to potentially sharpen. If None, no label is returned.

    Keyword Args:
        chance (float=0.5): The chance of sharpening a pixel.
        intensity (float=1.0): The intensity of the sharpening. from 0.0 to 1.0.
        apply_to_y (bool=False): Whether to sharpen the label as well.
        channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).
    &#34;&#34;&#34;
    if np.random.rand() &gt; chance:
        return X, y

    x_sharpened = X.astype(np.float32)
    y_sharpened = y.astype(np.float32) if y is not None else None

    offsets, weights = simple_unsharp_kernel_2d_3x3()
    channels = X.shape[2] if channel_last else X.shape[0]

    if channel_last:
        for channel in prange(channels):
            x_sharpened[:, :, channel] = convolution_simple(x_sharpened[:, :, channel], offsets, weights, intensity)
            if apply_to_y and y is not None:
                y_sharpened[:, :, channel] = convolution_simple(y_sharpened[:, :, channel], offsets, weights, intensity)
    else:
        for channel in prange(channels):
            x_sharpened[channel, :, :] = convolution_simple(x_sharpened[channel, :, :], offsets, weights, intensity)
            if apply_to_y and y is not None:
                y_sharpened[channel, :, :] = convolution_simple(y_sharpened[channel, :, :], offsets, weights, intensity)

    x_sharpened = fit_data_to_dtype(x_sharpened, X.dtype)
    y_sharpened = fit_data_to_dtype(y_sharpened, y.dtype) if y is not None else None

    return x_sharpened, y_sharpened


def augmentation_misalign_pixels(
    X: np.ndarray,
    y: Optional[np.ndarray],
    chance: float = 0.5,
    max_offset: float = 0.5,
    channel_last: bool = True,
) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:
    &#34;&#34;&#34;
    Misaligns one channel in the image at random.
    input should be (height, width, channels) or (channels, height, width).

    Args:
        X (np.ndarray): The image to potentially misalign the channels of.
        y (np.ndarray/None): The label to potentially misalign the channels of. If None, no label is returned.

    Keyword Args:
        chance (float=0.5): The chance of misaligning the channels of a pixel.
        max_offset (float=0.5): The maximum offset to misalign the channels by.
        channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).
    &#34;&#34;&#34;
    if np.random.rand() &gt; chance:
        return X, y

    x_misaligned = X.astype(np.float32)
    y_misaligned = y.astype(np.float32) if y is not None else None

    offsets, weights = simple_shift_kernel_2d(
        min(np.random.rand(), max_offset),
        min(np.random.rand(), max_offset),
    )

    channels = X.shape[2] if channel_last else X.shape[0]
    channel_to_drop = np.random.randint(0, channels)

    if channel_last:
        x_misaligned[:, :, channel_to_drop] = convolution_simple(x_misaligned[:, :, channel_to_drop], offsets, weights)
    else:
        x_misaligned[channel_to_drop, :, :] = convolution_simple(x_misaligned[channel_to_drop, :, :], offsets, weights)

    x_misaligned = fit_data_to_dtype(x_misaligned, X.dtype)
    y_misaligned = fit_data_to_dtype(y_misaligned, y.dtype) if y is not None else None

    return x_misaligned, y_misaligned


@jit(nopython=True, nogil=True, cache=True, fastmath=True, parallel=True)
def augmentation_cutmix(
    X_target: np.ndarray,
    y_target: np.ndarray,
    X_source: np.ndarray,
    y_source: np.ndarray,
    chance: float = 0.5,
    min_size: float = 0.333,
    max_size: float = 0.666,
    label_mix: int = 0,
    feather: bool = True,
    feather_dist: int = 3,
    channel_last: bool = True,
) -&gt; Tuple[np.ndarray, np.ndarray,]:
    &#34;&#34;&#34;
    Cutmixes two images.
    input should be (height, width, channels) or (channels, height, width).

    Args:
        X_target (np.ndarray): The image to transfer the cutmix to.
        y_target (np.ndarray): The label to transfer the cutmix to.
        X_source (np.ndarray): The image to cutmix from.
        y_source (np.ndarray): The label to cutmix from.

    Keyword Args:
        chance (float=0.5): The chance of cutmixing a pixel.
        min_size (float=0.333): The minimum size of the patch to cutmix. In percentage of the image width.
        max_size (float=0.666): The maximum size of the patch to cutmix. In percentage of the image width.
        label_mix (int=0): if
            0 - The labels will be mixed by the weights.\n
            1 - The target label will be used.\n
            2 - The source label will be used.\n
            3 - The max of the labels will be used.\n
            4 - The min of the labels will be used.\n
            5 - The max of the image with the highest weight will be used.\n
            6 - The min of the image with the highest weight will be used.\n
        feather (bool=True): Whether to feather the edges of the cutmix.
        feather_dist (int=3): The distance to feather the edges of the cutmix in pixels
        channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).
    &#34;&#34;&#34;
    if np.random.rand() &gt; chance:
        return X_target, y_target

    x_mixed = X_target.astype(np.float32)
    y_mixed = y_target.astype(np.float32)

    if channel_last:
        height, width, channels_x = x_mixed.shape
    else:
        channels_x, height, width = x_mixed.shape

    channels_y = y_mixed.shape[2] if channel_last else y_mixed.shape[0]

    patch_height = np.random.randint(int(height * min_size), int(height * max_size))
    patch_width = np.random.randint(int(width * min_size), int(width * max_size))

    if feather:
        patch_height += feather_dist * 2
        patch_width += feather_dist * 2

        patch_height = min(patch_height, height)
        patch_width = min(patch_width, width)

    x0 = np.random.randint(0, width - patch_width)
    y0 = np.random.randint(0, height - patch_height)
    x1 = x0 + patch_width
    y1 = y0 + patch_height

    if feather:
        bbox = np.array([x0, x1, y0, y1])
        feather_weight_target = feather_box_2d(x_mixed, bbox, feather_dist)
        feather_weight_source = 1 - feather_weight_target

        x0 = max(0, x0 - feather_dist)
        x1 = min(x1 + 1 + feather_dist, x_mixed.shape[1])
        y0 = max(0, y0 - feather_dist)
        y1 = min(y1 + 1 + feather_dist, x_mixed.shape[0])

        if channel_last: # Reshape and tile instead of slicing, because of Numba.
            for col in prange(y0, y1):
                for row in prange(x0, x1):
                    for channel_x in prange(channels_x):
                        x_mixed[col, row, channel_x] = (
                            x_mixed[col, row, channel_x] * feather_weight_target[col, row][0]
                            + X_source[col, row, channel_x] * feather_weight_source[col, row][0]
                        )

                    for channel_y in prange(channels_y):
                        if label_mix == 0:
                            y_mixed[col, row, channel_y] = (
                                y_mixed[col, row, channel_y] * feather_weight_target[col, row][0]
                                + y_source[col, row, channel_y] * feather_weight_source[col, row][0]
                            )
                        elif label_mix == 1:
                            y_mixed[col, row, channel_y] = y_mixed[col, row, channel_y]
                        elif label_mix == 2:
                            y_mixed[col, row, channel_y] = y_source[col, row, channel_y]
                        elif label_mix == 3:
                            y_mixed[col, row, channel_y] = max(
                                y_mixed[col, row, channel_y], y_source[col, row, channel_y]
                            )
                        elif label_mix == 4:
                            y_mixed[col, row, channel_y] = min(
                                y_mixed[col, row, channel_y], y_source[col, row, channel_y]
                            )
                        elif label_mix == 5:
                            if feather_weight_target[col, row][0] &gt; feather_weight_source[col, row][0]:
                                y_mixed[col, row, channel_y] = y_mixed[col, row, channel_y]
                            else:
                                y_mixed[col, row, channel_y] = y_source[col, row, channel_y]
                        elif label_mix == 6:
                            if feather_weight_target[col, row][0] &lt; feather_weight_source[col, row][0]:
                                y_mixed[col, row, channel_y] = y_mixed[col, row, channel_y]
                            else:
                                y_mixed[col, row, channel_y] = y_source[col, row, channel_y]
        else:
            for col in prange(y0, y1):
                for row in prange(x0, x1):
                    for channel_x in prange(channels_x):
                        x_mixed[channel_x, col, row] = (
                            x_mixed[channel_x, col, row] * feather_weight_target[col, row][0]
                            + X_source[channel_x, col, row] * feather_weight_source[col, row][0]
                        )

                    for channel_y in prange(channels_y):
                        if label_mix == 0:
                            y_mixed[channel_y, col, row] = (
                                y_mixed[channel_y, col, row] * feather_weight_target[col, row][0]
                                + y_source[channel_y, col, row] * feather_weight_source[col, row][0]
                            )
                        elif label_mix == 1:
                            y_mixed[channel_y, col, row] = y_mixed[channel_y, col, row]
                        elif label_mix == 2:
                            y_mixed[channel_y, col, row] = y_source[channel_y, col, row]
                        elif label_mix == 3:
                            y_mixed[channel_y, col, row] = max(
                                y_mixed[channel_y, col, row], y_source[channel_y, col, row]
                            )
                        elif label_mix == 4:
                            y_mixed[channel_y, col, row] = min(
                                y_mixed[channel_y, col, row], y_source[channel_y, col, row]
                            )
                        elif label_mix == 5:
                            if feather_weight_target[col, row][0] &gt; feather_weight_source[col, row][0]:
                                y_mixed[channel_y, col, row] = y_mixed[channel_y, col, row]
                            else:
                                y_mixed[channel_y, col, row] = y_source[channel_y, col, row]
                        elif label_mix == 6:
                            if feather_weight_target[col, row][0] &lt; feather_weight_source[col, row][0]:
                                y_mixed[channel_y, col, row] = y_mixed[channel_y, col, row]
                            else:
                                y_mixed[channel_y, col, row] = y_source[channel_y, col, row]

    else:
        if channel_last:
            x_mixed[y0:y1, x0:x1, :] = X_source[y0:y1, x0:x1, :]
            y_mixed[y0:y1, x0:x1, :] = y_source[y0:y1, x0:x1, :]

        else:
            x_mixed[:, y0:y1, x0:x1] = X_source[:, y0:y1, x0:x1]
            y_mixed[:, y0:y1, x0:x1] = y_source[:, y0:y1, x0:x1]

    return (
        fit_data_to_dtype(x_mixed, X_target.dtype),
        fit_data_to_dtype(y_mixed, y_target.dtype),
    )


@jit(nopython=True, nogil=True, cache=True, fastmath=True, parallel=True)
def augmentation_mixup(
    X_target: np.ndarray,
    y_target: np.ndarray,
    X_source: np.ndarray,
    y_source: np.ndarray,
    min_mix: float = 0.333,
    max_mix: float = 0.666,
    label_mix: int = 0,
    chance: float = 0.5,
    channel_last: bool = True, # pylint: disable=unused-argument
) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:
    &#34;&#34;&#34;
    Mixups two images at random. This works by doing a linear intepolation between
    two images and then adding a random weight to each image.

    Mixup involves taking two images and blending them together by randomly interpolating
    their pixel values. More specifically, suppose we have two images x and x&#39; with their
    corresponding labels y and y&#39;. To generate a new training example, mixup takes a
    weighted sum of x and x&#39;, such that the resulting image x^* = λx + (1-λ)x&#39;,
    where λ is a randomly chosen interpolation coefficient. The label for the new image
    is also a weighted sum of y and y&#39; based on the same interpolation coefficient.

    input should be (height, width, channels) or (channels, height, width).

    Args:
        X_target (np.ndarray): The image to transfer to.
        y_target (np.ndarray): The label to transfer to.
        X_source (np.ndarray): The image to transfer from.
        y_source (np.ndarray): The label to transfer from.

    Keyword Args:
        min_mix (float=0.333): The minimum mixup coefficient.
        max_mix (float=0.666): The maximum mixup coefficient.
        label_mix (int=0): if
            0 - The labels will be mixed by the weights.\n
            1 - The target label will be used.\n
            2 - The source label will be used.\n
            3 - The max of the labels will be used.\n
            4 - The min of the labels will be used.\n
            5 - The max of the image with the highest weight will be used.\n
            6 - The min of the image with the highest weight will be used.\n
        chance (float=0.5): The chance of mixuping a pixel.
        channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).
    &#34;&#34;&#34;
    if np.random.rand() &gt; chance:
        return X_target, y_target

    x_mixed = X_target.astype(np.float32)
    y_mixed = y_target.astype(np.float32)

    mixup_coeff = np.random.uniform(min_mix, max_mix + 0.001)

    x_mixed = x_mixed * mixup_coeff + X_source * (1 - mixup_coeff)

    if label_mix == 0:
        y_mixed = y_mixed * mixup_coeff + y_source * (1 - mixup_coeff)
    elif label_mix == 1:
        y_mixed = y_target
    elif label_mix == 2:
        y_mixed = y_source
    elif label_mix == 3:
        y_mixed = np.maximum(y_target, y_source)
    elif label_mix == 4:
        y_mixed = np.minimum(y_target, y_source)
    elif label_mix == 5:
        y_mixed = y_target if mixup_coeff &gt;= 0.5 else y_source
    elif label_mix == 6:
        y_mixed = y_target if mixup_coeff &gt;= 0.5 else y_source

    return (
        fit_data_to_dtype(x_mixed, X_target.dtype),
        fit_data_to_dtype(y_mixed, y_target.dtype),
    )</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="buteo.ai.augmentation_funcs.augmentation_blur"><code class="name flex">
<span>def <span class="ident">augmentation_blur</span></span>(<span>X: numpy.ndarray, y: Optional[numpy.ndarray], chance: float = 0.5, intensity: float = 1.0, apply_to_y: bool = False, channel_last: bool = True) -> Tuple[numpy.ndarray, Optional[numpy.ndarray]]</span>
</code></dt>
<dd>
<div class="desc"><p>Blurs an image at random.
input should be (height, width, channels) or (channels, height, width).
Same goes for the label if apply_to_y is True.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The image to potentially blur.</dd>
</dl>
<p>y (np.ndarray/None): The label to potentially blur. If None, no label is returned.
Keyword Args:
chance (float=0.5): The chance of blurring a pixel.
intensity (float=1.0): The intensity of the blur. from 0.0 to 1.0.
apply_to_y (bool=False): Whether to blur the label as well.
channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@jit(nopython=True, nogil=True, cache=True, fastmath=True, parallel=True)
def augmentation_blur(
    X: np.ndarray,
    y: Optional[np.ndarray],
    chance: float = 0.5,
    intensity: float = 1.0,
    apply_to_y: bool = False,
    channel_last: bool = True,
) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:
    &#34;&#34;&#34;
    Blurs an image at random.
    input should be (height, width, channels) or (channels, height, width).
    Same goes for the label if apply_to_y is True.

    Args:
        X (np.ndarray): The image to potentially blur.
        y (np.ndarray/None): The label to potentially blur. If None, no label is returned.

    Keyword Args:
        chance (float=0.5): The chance of blurring a pixel.
        intensity (float=1.0): The intensity of the blur. from 0.0 to 1.0.
        apply_to_y (bool=False): Whether to blur the label as well.
        channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).
    &#34;&#34;&#34;
    if np.random.rand() &gt; chance:
        return X, y

    x_blurred = X.astype(np.float32)
    y_blurred = y.astype(np.float32) if y is not None else None

    offsets, weights = simple_blur_kernel_2d_3x3()
    channels = X.shape[2] if channel_last else X.shape[0]

    if channel_last:
        for channel in prange(channels):
            x_blurred[:, :, channel] = convolution_simple(x_blurred[:, :, channel], offsets, weights, intensity)
            if apply_to_y and y is not None:
                y_blurred[:, :, channel] = convolution_simple(y_blurred[:, :, channel], offsets, weights, intensity)
    else:
        for channel in prange(channels):
            x_blurred[channel, :, :] = convolution_simple(x_blurred[channel, :, :], offsets, weights, intensity)
            if apply_to_y and y is not None:
                y_blurred[channel, :, :] = convolution_simple(y_blurred[channel, :, :], offsets, weights, intensity)

    x_blurred = fit_data_to_dtype(x_blurred, X.dtype)
    y_blurred = fit_data_to_dtype(y_blurred, y.dtype) if y is not None else None

    return x_blurred, y_blurred</code></pre>
</details>
</dd>
<dt id="buteo.ai.augmentation_funcs.augmentation_channel_scale"><code class="name flex">
<span>def <span class="ident">augmentation_channel_scale</span></span>(<span>X: numpy.ndarray, y: Optional[numpy.ndarray], chance: float = 0.5, max_amount: float = 0.1, additive: bool = False, channel_last: bool = True) -> Tuple[numpy.ndarray, Optional[numpy.ndarray]]</span>
</code></dt>
<dd>
<div class="desc"><p>Scales the channels of the image seperately by a fixed amount.
input should be (height, width, channels) or (channels, height, width).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The image to scale the channels of.</dd>
</dl>
<p>y (np.ndarray/None): The label to scale the channels of. If None, no label is returned.
Keyword Args:
chance (float=0.5): The chance of scaling the channels.
max_amount (float=0.1): The amount to possible scale the channels by. Sampled uniformly.
additive (bool=False): Whether to add or multiply the scaling.
channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Tuple[np.ndarray, Optional[np.ndarray]]</code></dt>
<dd>The image with scaled channels and optionally the unmodified label.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@jit(nopython=True, nogil=True, cache=True, fastmath=True, parallel=True)
def augmentation_channel_scale(
    X: np.ndarray,
    y: Optional[np.ndarray],
    chance: float = 0.5,
    max_amount: float = 0.1,
    additive: bool = False,
    channel_last: bool = True,
) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:
    &#34;&#34;&#34;
    Scales the channels of the image seperately by a fixed amount.
    input should be (height, width, channels) or (channels, height, width).

    Args:
        X (np.ndarray): The image to scale the channels of.
        y (np.ndarray/None): The label to scale the channels of. If None, no label is returned.

    Keyword Args:
        chance (float=0.5): The chance of scaling the channels.
        max_amount (float=0.1): The amount to possible scale the channels by. Sampled uniformly.
        additive (bool=False): Whether to add or multiply the scaling.
        channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).

    Returns:
        Tuple[np.ndarray, Optional[np.ndarray]]: The image with scaled channels and optionally the unmodified label.
    &#34;&#34;&#34;
    if np.random.rand() &gt; chance:
        return X, y

    x_scaled = X.astype(np.float32)
    y_scaled = y

    amount = np.random.rand() * max_amount

    if channel_last:
        for i in prange(X.shape[2]):
            if additive:
                random_amount = np.random.uniform(-amount, amount)
                x_scaled[:, :, i] += random_amount
            else:
                random_amount = np.random.uniform(1 - amount, 1 + amount)
                x_scaled[:, :, i] *= random_amount
    else:
        for i in prange(X.shape[0]):
            if additive:
                random_amount = np.random.uniform(-amount, amount)
                x_scaled[i, :, :] += random_amount
            else:
                random_amount = np.random.uniform(1 - amount, 1 + amount)
                x_scaled[i, :, :] *= random_amount

    return fit_data_to_dtype(x_scaled, X.dtype), y_scaled</code></pre>
</details>
</dd>
<dt id="buteo.ai.augmentation_funcs.augmentation_contrast"><code class="name flex">
<span>def <span class="ident">augmentation_contrast</span></span>(<span>X: numpy.ndarray, y: Optional[numpy.ndarray], chance: float = 0.5, max_amount: float = 0.1, channel_last: bool = True) -> Tuple[numpy.ndarray, Optional[numpy.ndarray]]</span>
</code></dt>
<dd>
<div class="desc"><p>Changes the contrast of an image by a random amount, seperately for each channel.
input should be (height, width, channels) or (channels, height, width).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The image to change the contrast of.</dd>
</dl>
<p>y (np.ndarray/None): The label to change the contrast of. If None, no label is returned.
Keyword Args:
chance (float=0.5): The chance of changing the contrast.
max_amount (float=0.1): The max amount to change the contrast by.
channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Tuple[np.ndarray, Optional[np.ndarray]]</code></dt>
<dd>The image with changed contrast and optionally the unmodified label.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@jit(nopython=True, nogil=True, cache=True, fastmath=True, parallel=True)
def augmentation_contrast(
    X: np.ndarray,
    y: Optional[np.ndarray],
    chance: float = 0.5,
    max_amount: float = 0.1,
    channel_last: bool = True,
) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:
    &#34;&#34;&#34;
    Changes the contrast of an image by a random amount, seperately for each channel.
    input should be (height, width, channels) or (channels, height, width).

    Args:
        X (np.ndarray): The image to change the contrast of.
        y (np.ndarray/None): The label to change the contrast of. If None, no label is returned.

    Keyword Args:
        chance (float=0.5): The chance of changing the contrast.
        max_amount (float=0.1): The max amount to change the contrast by.
        channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).

    Returns:
        Tuple[np.ndarray, Optional[np.ndarray]]: The image with changed contrast and optionally the unmodified label.
    &#34;&#34;&#34;
    if np.random.rand() &gt; chance:
        return X, y

    x_contrast = X.astype(np.float32)
    y_contrast = y

    amount = np.random.rand() * max_amount

    channels = X.shape[2] if channel_last else X.shape[0]
    mean_pixel = np.array([0.0] * channels, dtype=np.float32)

    # Numba workaround
    if channel_last:
        for i in prange(channels):
            mean_pixel[i] = np.mean(x_contrast[:, :, i])
    else:
        for i in prange(channels):
            mean_pixel[i] = np.mean(x_contrast[i])

    for i in prange(channels):
        x_contrast[:, :, i] = (x_contrast[:, :, i] - mean_pixel[i]) * (1 + amount) + mean_pixel[i]

    return fit_data_to_dtype(x_contrast, X.dtype), y_contrast</code></pre>
</details>
</dd>
<dt id="buteo.ai.augmentation_funcs.augmentation_cutmix"><code class="name flex">
<span>def <span class="ident">augmentation_cutmix</span></span>(<span>X_target: numpy.ndarray, y_target: numpy.ndarray, X_source: numpy.ndarray, y_source: numpy.ndarray, chance: float = 0.5, min_size: float = 0.333, max_size: float = 0.666, label_mix: int = 0, feather: bool = True, feather_dist: int = 3, channel_last: bool = True) -> Tuple[numpy.ndarray, numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"><p>Cutmixes two images.
input should be (height, width, channels) or (channels, height, width).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>X_target</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The image to transfer the cutmix to.</dd>
<dt><strong><code>y_target</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The label to transfer the cutmix to.</dd>
<dt><strong><code>X_source</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The image to cutmix from.</dd>
<dt><strong><code>y_source</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The label to cutmix from.</dd>
</dl>
<p>Keyword Args:
chance (float=0.5): The chance of cutmixing a pixel.
min_size (float=0.333): The minimum size of the patch to cutmix. In percentage of the image width.
max_size (float=0.666): The maximum size of the patch to cutmix. In percentage of the image width.
label_mix (int=0): if
0 - The labels will be mixed by the weights.</p>
<pre><code>    1 - The target label will be used.

    2 - The source label will be used.

    3 - The max of the labels will be used.

    4 - The min of the labels will be used.

    5 - The max of the image with the highest weight will be used.

    6 - The min of the image with the highest weight will be used.

feather (bool=True): Whether to feather the edges of the cutmix.
feather_dist (int=3): The distance to feather the edges of the cutmix in pixels
channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@jit(nopython=True, nogil=True, cache=True, fastmath=True, parallel=True)
def augmentation_cutmix(
    X_target: np.ndarray,
    y_target: np.ndarray,
    X_source: np.ndarray,
    y_source: np.ndarray,
    chance: float = 0.5,
    min_size: float = 0.333,
    max_size: float = 0.666,
    label_mix: int = 0,
    feather: bool = True,
    feather_dist: int = 3,
    channel_last: bool = True,
) -&gt; Tuple[np.ndarray, np.ndarray,]:
    &#34;&#34;&#34;
    Cutmixes two images.
    input should be (height, width, channels) or (channels, height, width).

    Args:
        X_target (np.ndarray): The image to transfer the cutmix to.
        y_target (np.ndarray): The label to transfer the cutmix to.
        X_source (np.ndarray): The image to cutmix from.
        y_source (np.ndarray): The label to cutmix from.

    Keyword Args:
        chance (float=0.5): The chance of cutmixing a pixel.
        min_size (float=0.333): The minimum size of the patch to cutmix. In percentage of the image width.
        max_size (float=0.666): The maximum size of the patch to cutmix. In percentage of the image width.
        label_mix (int=0): if
            0 - The labels will be mixed by the weights.\n
            1 - The target label will be used.\n
            2 - The source label will be used.\n
            3 - The max of the labels will be used.\n
            4 - The min of the labels will be used.\n
            5 - The max of the image with the highest weight will be used.\n
            6 - The min of the image with the highest weight will be used.\n
        feather (bool=True): Whether to feather the edges of the cutmix.
        feather_dist (int=3): The distance to feather the edges of the cutmix in pixels
        channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).
    &#34;&#34;&#34;
    if np.random.rand() &gt; chance:
        return X_target, y_target

    x_mixed = X_target.astype(np.float32)
    y_mixed = y_target.astype(np.float32)

    if channel_last:
        height, width, channels_x = x_mixed.shape
    else:
        channels_x, height, width = x_mixed.shape

    channels_y = y_mixed.shape[2] if channel_last else y_mixed.shape[0]

    patch_height = np.random.randint(int(height * min_size), int(height * max_size))
    patch_width = np.random.randint(int(width * min_size), int(width * max_size))

    if feather:
        patch_height += feather_dist * 2
        patch_width += feather_dist * 2

        patch_height = min(patch_height, height)
        patch_width = min(patch_width, width)

    x0 = np.random.randint(0, width - patch_width)
    y0 = np.random.randint(0, height - patch_height)
    x1 = x0 + patch_width
    y1 = y0 + patch_height

    if feather:
        bbox = np.array([x0, x1, y0, y1])
        feather_weight_target = feather_box_2d(x_mixed, bbox, feather_dist)
        feather_weight_source = 1 - feather_weight_target

        x0 = max(0, x0 - feather_dist)
        x1 = min(x1 + 1 + feather_dist, x_mixed.shape[1])
        y0 = max(0, y0 - feather_dist)
        y1 = min(y1 + 1 + feather_dist, x_mixed.shape[0])

        if channel_last: # Reshape and tile instead of slicing, because of Numba.
            for col in prange(y0, y1):
                for row in prange(x0, x1):
                    for channel_x in prange(channels_x):
                        x_mixed[col, row, channel_x] = (
                            x_mixed[col, row, channel_x] * feather_weight_target[col, row][0]
                            + X_source[col, row, channel_x] * feather_weight_source[col, row][0]
                        )

                    for channel_y in prange(channels_y):
                        if label_mix == 0:
                            y_mixed[col, row, channel_y] = (
                                y_mixed[col, row, channel_y] * feather_weight_target[col, row][0]
                                + y_source[col, row, channel_y] * feather_weight_source[col, row][0]
                            )
                        elif label_mix == 1:
                            y_mixed[col, row, channel_y] = y_mixed[col, row, channel_y]
                        elif label_mix == 2:
                            y_mixed[col, row, channel_y] = y_source[col, row, channel_y]
                        elif label_mix == 3:
                            y_mixed[col, row, channel_y] = max(
                                y_mixed[col, row, channel_y], y_source[col, row, channel_y]
                            )
                        elif label_mix == 4:
                            y_mixed[col, row, channel_y] = min(
                                y_mixed[col, row, channel_y], y_source[col, row, channel_y]
                            )
                        elif label_mix == 5:
                            if feather_weight_target[col, row][0] &gt; feather_weight_source[col, row][0]:
                                y_mixed[col, row, channel_y] = y_mixed[col, row, channel_y]
                            else:
                                y_mixed[col, row, channel_y] = y_source[col, row, channel_y]
                        elif label_mix == 6:
                            if feather_weight_target[col, row][0] &lt; feather_weight_source[col, row][0]:
                                y_mixed[col, row, channel_y] = y_mixed[col, row, channel_y]
                            else:
                                y_mixed[col, row, channel_y] = y_source[col, row, channel_y]
        else:
            for col in prange(y0, y1):
                for row in prange(x0, x1):
                    for channel_x in prange(channels_x):
                        x_mixed[channel_x, col, row] = (
                            x_mixed[channel_x, col, row] * feather_weight_target[col, row][0]
                            + X_source[channel_x, col, row] * feather_weight_source[col, row][0]
                        )

                    for channel_y in prange(channels_y):
                        if label_mix == 0:
                            y_mixed[channel_y, col, row] = (
                                y_mixed[channel_y, col, row] * feather_weight_target[col, row][0]
                                + y_source[channel_y, col, row] * feather_weight_source[col, row][0]
                            )
                        elif label_mix == 1:
                            y_mixed[channel_y, col, row] = y_mixed[channel_y, col, row]
                        elif label_mix == 2:
                            y_mixed[channel_y, col, row] = y_source[channel_y, col, row]
                        elif label_mix == 3:
                            y_mixed[channel_y, col, row] = max(
                                y_mixed[channel_y, col, row], y_source[channel_y, col, row]
                            )
                        elif label_mix == 4:
                            y_mixed[channel_y, col, row] = min(
                                y_mixed[channel_y, col, row], y_source[channel_y, col, row]
                            )
                        elif label_mix == 5:
                            if feather_weight_target[col, row][0] &gt; feather_weight_source[col, row][0]:
                                y_mixed[channel_y, col, row] = y_mixed[channel_y, col, row]
                            else:
                                y_mixed[channel_y, col, row] = y_source[channel_y, col, row]
                        elif label_mix == 6:
                            if feather_weight_target[col, row][0] &lt; feather_weight_source[col, row][0]:
                                y_mixed[channel_y, col, row] = y_mixed[channel_y, col, row]
                            else:
                                y_mixed[channel_y, col, row] = y_source[channel_y, col, row]

    else:
        if channel_last:
            x_mixed[y0:y1, x0:x1, :] = X_source[y0:y1, x0:x1, :]
            y_mixed[y0:y1, x0:x1, :] = y_source[y0:y1, x0:x1, :]

        else:
            x_mixed[:, y0:y1, x0:x1] = X_source[:, y0:y1, x0:x1]
            y_mixed[:, y0:y1, x0:x1] = y_source[:, y0:y1, x0:x1]

    return (
        fit_data_to_dtype(x_mixed, X_target.dtype),
        fit_data_to_dtype(y_mixed, y_target.dtype),
    )</code></pre>
</details>
</dd>
<dt id="buteo.ai.augmentation_funcs.augmentation_drop_channel"><code class="name flex">
<span>def <span class="ident">augmentation_drop_channel</span></span>(<span>X: numpy.ndarray, y: Optional[numpy.ndarray], chance: float = 0.5, drop_probability: float = 0.1, drop_value: float = 0.0, channel_last: bool = True) -> Tuple[numpy.ndarray, Optional[numpy.ndarray]]</span>
</code></dt>
<dd>
<div class="desc"><p>Drops a random channel from an image.
input should be (height, width, channels) or (channels, height, width).
A maximum of one channel will be dropped.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The image to drop a channel from.</dd>
</dl>
<p>y (np.ndarray/None): The label to drop a channel from. If None, no label is returned.
Keyword Args:
chance (float=0.5): The chance of dropping a channel.
drop_probability (float=0.1): The probability of dropping a channel.
drop_value (float=0.0): The value to drop the channel to.
channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@jit(nopython=True, nogil=True, cache=True, fastmath=True)
def augmentation_drop_channel(
    X: np.ndarray,
    y: Optional[np.ndarray],
    chance: float = 0.5,
    drop_probability: float = 0.1,
    drop_value: float = 0.0,
    channel_last: bool = True,
) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:
    &#34;&#34;&#34;
    Drops a random channel from an image.
    input should be (height, width, channels) or (channels, height, width).
    A maximum of one channel will be dropped.

    Args:
        X (np.ndarray): The image to drop a channel from.
        y (np.ndarray/None): The label to drop a channel from. If None, no label is returned.

    Keyword Args:
        chance (float=0.5): The chance of dropping a channel.
        drop_probability (float=0.1): The probability of dropping a channel.
        drop_value (float=0.0): The value to drop the channel to.
        channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).
    &#34;&#34;&#34;
    if np.random.rand() &gt; chance:
        return X, y

    x_dropped = X.copy()
    y_dropped = y

    channels = X.shape[2] if channel_last else X.shape[0]

    drop_a_channel = False
    for _ in range(channels):
        if np.random.rand() &lt; drop_probability:
            drop_a_channel = True
            break

    if not drop_a_channel:
        return X, y

    channel_to_drop = np.random.randint(0, channels)

    if channel_last:
        x_dropped[:, :, channel_to_drop] = drop_value
    else:
        x_dropped[channel_to_drop, :, :] = drop_value

    return x_dropped, y_dropped</code></pre>
</details>
</dd>
<dt id="buteo.ai.augmentation_funcs.augmentation_drop_pixel"><code class="name flex">
<span>def <span class="ident">augmentation_drop_pixel</span></span>(<span>X: numpy.ndarray, y: Optional[numpy.ndarray], chance: float = 0.5, drop_probability: float = 0.01, drop_value: float = 0.0, channel_last: bool = True) -> Tuple[numpy.ndarray, Optional[numpy.ndarray]]</span>
</code></dt>
<dd>
<div class="desc"><p>Drops a random pixels from an image.
input should be (height, width, channels) or (channels, height, width).
Only drops pixels from features, not labels.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The image to drop a pixel from.</dd>
</dl>
<p>y (np.ndarray/None): The label to drop a pixel from. If None, no label is returned.
Keyword Args:
chance (float=0.5): The chance of dropping a pixel.
drop_probability (float=0.05): The probability of dropping a pixel.
drop_value (float=0.0): The value to drop the pixel to.
apply_to_y (bool=False): Whether to apply the drop to the label.
channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Tuple[np.ndarray, Optional[np.ndarray]]</code></dt>
<dd>The image with the dropped pixels and optionally the unmodified label.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@jit(nopython=True, nogil=True, cache=True, fastmath=True, parallel=True)
def augmentation_drop_pixel(
    X: np.ndarray,
    y: Optional[np.ndarray],
    chance: float = 0.5,
    drop_probability: float = 0.01,
    drop_value: float = 0.0,
    channel_last: bool = True,
) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:
    &#34;&#34;&#34;
    Drops a random pixels from an image.
    input should be (height, width, channels) or (channels, height, width).
    Only drops pixels from features, not labels.

    Args:
        X (np.ndarray): The image to drop a pixel from.
        y (np.ndarray/None): The label to drop a pixel from. If None, no label is returned.

    Keyword Args:
        chance (float=0.5): The chance of dropping a pixel.
        drop_probability (float=0.05): The probability of dropping a pixel.
        drop_value (float=0.0): The value to drop the pixel to.
        apply_to_y (bool=False): Whether to apply the drop to the label.
        channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).

    Returns:
        Tuple[np.ndarray, Optional[np.ndarray]]: The image with the dropped pixels and optionally the unmodified label.
    &#34;&#34;&#34;
    if np.random.rand() &gt; chance:
        return X, y

    x_dropped = X.copy()
    y_dropped = y

    mask = np.random.random(size=x_dropped.shape)

    # Agreed. This looks terrible. But it&#39;s the only way to get numba to parallelize this.
    if channel_last:
        for col in prange(X.shape[0]):
            for row in prange(X.shape[1]):
                for channel in prange(X.shape[2]):
                    if mask[col, row, channel] &lt;= drop_probability:
                        x_dropped[col, row, channel] = drop_value

    else:
        for channel in prange(X.shape[0]):
            for col in prange(X.shape[1]):
                for row in prange(X.shape[2]):
                    if mask[channel, col, row] &lt;= drop_probability:
                        x_dropped[channel, col, row] = drop_value

    return x_dropped, y_dropped</code></pre>
</details>
</dd>
<dt id="buteo.ai.augmentation_funcs.augmentation_mirror"><code class="name flex">
<span>def <span class="ident">augmentation_mirror</span></span>(<span>X: numpy.ndarray, y: Optional[numpy.ndarray], chance: float = 0.5, k: Optional[int] = None, channel_last: bool = True) -> Tuple[numpy.ndarray, Optional[numpy.ndarray]]</span>
</code></dt>
<dd>
<div class="desc"><p>Randomly mirrors the image. Images can be (channels, height, width) or (height, width, channels).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The image to mirror.</dd>
</dl>
<p>y (np.ndarray/None): The label to mirror.
Keyword Args:
chance (float=0.5): The chance of mirroring the image.
k (int=None): If None, randomly mirrors the image along the horizontal or vertical axis.
If 1, mirrors the image along the horizontal axis.
If 2, mirrors the image along the vertical axis.
If 3, mirrors the image along both the horizontal and vertical axis.
channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Tuple[np.ndarray, Optional[np.ndarray]]</code></dt>
<dd>The mirrored image and optionally the label.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@jit(nopython=True, nogil=True, cache=True, fastmath=True)
def augmentation_mirror(
    X: np.ndarray,
    y: Optional[np.ndarray],
    chance: float = 0.5,
    k: Optional[int] = None,
    channel_last: bool = True,
) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:
    &#34;&#34;&#34;
    Randomly mirrors the image. Images can be (channels, height, width) or (height, width, channels).

    Args:
        X (np.ndarray): The image to mirror.
        y (np.ndarray/None): The label to mirror.

    Keyword Args:
        chance (float=0.5): The chance of mirroring the image.
        k (int=None): If None, randomly mirrors the image along the horizontal or vertical axis.
            If 1, mirrors the image along the horizontal axis.
            If 2, mirrors the image along the vertical axis.
            If 3, mirrors the image along both the horizontal and vertical axis.
        channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).

    Returns:
        Tuple[np.ndarray, Optional[np.ndarray]]: The mirrored image and optionally the label.
    &#34;&#34;&#34;
    if np.random.rand() &gt; chance or k == 0:
        return X, y

    random_k = np.random.randint(1, 4) if k is None else k

    flipped_x = mirror_arr(X, random_k, channel_last)
    flipped_y = mirror_arr(y, random_k, channel_last) if y is not None else None

    return flipped_x, flipped_y</code></pre>
</details>
</dd>
<dt id="buteo.ai.augmentation_funcs.augmentation_misalign_pixels"><code class="name flex">
<span>def <span class="ident">augmentation_misalign_pixels</span></span>(<span>X: numpy.ndarray, y: Optional[numpy.ndarray], chance: float = 0.5, max_offset: float = 0.5, channel_last: bool = True) -> Tuple[numpy.ndarray, Optional[numpy.ndarray]]</span>
</code></dt>
<dd>
<div class="desc"><p>Misaligns one channel in the image at random.
input should be (height, width, channels) or (channels, height, width).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The image to potentially misalign the channels of.</dd>
</dl>
<p>y (np.ndarray/None): The label to potentially misalign the channels of. If None, no label is returned.
Keyword Args:
chance (float=0.5): The chance of misaligning the channels of a pixel.
max_offset (float=0.5): The maximum offset to misalign the channels by.
channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def augmentation_misalign_pixels(
    X: np.ndarray,
    y: Optional[np.ndarray],
    chance: float = 0.5,
    max_offset: float = 0.5,
    channel_last: bool = True,
) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:
    &#34;&#34;&#34;
    Misaligns one channel in the image at random.
    input should be (height, width, channels) or (channels, height, width).

    Args:
        X (np.ndarray): The image to potentially misalign the channels of.
        y (np.ndarray/None): The label to potentially misalign the channels of. If None, no label is returned.

    Keyword Args:
        chance (float=0.5): The chance of misaligning the channels of a pixel.
        max_offset (float=0.5): The maximum offset to misalign the channels by.
        channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).
    &#34;&#34;&#34;
    if np.random.rand() &gt; chance:
        return X, y

    x_misaligned = X.astype(np.float32)
    y_misaligned = y.astype(np.float32) if y is not None else None

    offsets, weights = simple_shift_kernel_2d(
        min(np.random.rand(), max_offset),
        min(np.random.rand(), max_offset),
    )

    channels = X.shape[2] if channel_last else X.shape[0]
    channel_to_drop = np.random.randint(0, channels)

    if channel_last:
        x_misaligned[:, :, channel_to_drop] = convolution_simple(x_misaligned[:, :, channel_to_drop], offsets, weights)
    else:
        x_misaligned[channel_to_drop, :, :] = convolution_simple(x_misaligned[channel_to_drop, :, :], offsets, weights)

    x_misaligned = fit_data_to_dtype(x_misaligned, X.dtype)
    y_misaligned = fit_data_to_dtype(y_misaligned, y.dtype) if y is not None else None

    return x_misaligned, y_misaligned</code></pre>
</details>
</dd>
<dt id="buteo.ai.augmentation_funcs.augmentation_mixup"><code class="name flex">
<span>def <span class="ident">augmentation_mixup</span></span>(<span>X_target: numpy.ndarray, y_target: numpy.ndarray, X_source: numpy.ndarray, y_source: numpy.ndarray, min_mix: float = 0.333, max_mix: float = 0.666, label_mix: int = 0, chance: float = 0.5, channel_last: bool = True) -> Tuple[numpy.ndarray, Optional[numpy.ndarray]]</span>
</code></dt>
<dd>
<div class="desc"><p>Mixups two images at random. This works by doing a linear intepolation between
two images and then adding a random weight to each image.</p>
<p>Mixup involves taking two images and blending them together by randomly interpolating
their pixel values. More specifically, suppose we have two images x and x' with their
corresponding labels y and y'. To generate a new training example, mixup takes a
weighted sum of x and x', such that the resulting image x^* = λx + (1-λ)x',
where λ is a randomly chosen interpolation coefficient. The label for the new image
is also a weighted sum of y and y' based on the same interpolation coefficient.</p>
<p>input should be (height, width, channels) or (channels, height, width).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>X_target</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The image to transfer to.</dd>
<dt><strong><code>y_target</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The label to transfer to.</dd>
<dt><strong><code>X_source</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The image to transfer from.</dd>
<dt><strong><code>y_source</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The label to transfer from.</dd>
</dl>
<p>Keyword Args:
min_mix (float=0.333): The minimum mixup coefficient.
max_mix (float=0.666): The maximum mixup coefficient.
label_mix (int=0): if
0 - The labels will be mixed by the weights.</p>
<pre><code>    1 - The target label will be used.

    2 - The source label will be used.

    3 - The max of the labels will be used.

    4 - The min of the labels will be used.

    5 - The max of the image with the highest weight will be used.

    6 - The min of the image with the highest weight will be used.

chance (float=0.5): The chance of mixuping a pixel.
channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@jit(nopython=True, nogil=True, cache=True, fastmath=True, parallel=True)
def augmentation_mixup(
    X_target: np.ndarray,
    y_target: np.ndarray,
    X_source: np.ndarray,
    y_source: np.ndarray,
    min_mix: float = 0.333,
    max_mix: float = 0.666,
    label_mix: int = 0,
    chance: float = 0.5,
    channel_last: bool = True, # pylint: disable=unused-argument
) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:
    &#34;&#34;&#34;
    Mixups two images at random. This works by doing a linear intepolation between
    two images and then adding a random weight to each image.

    Mixup involves taking two images and blending them together by randomly interpolating
    their pixel values. More specifically, suppose we have two images x and x&#39; with their
    corresponding labels y and y&#39;. To generate a new training example, mixup takes a
    weighted sum of x and x&#39;, such that the resulting image x^* = λx + (1-λ)x&#39;,
    where λ is a randomly chosen interpolation coefficient. The label for the new image
    is also a weighted sum of y and y&#39; based on the same interpolation coefficient.

    input should be (height, width, channels) or (channels, height, width).

    Args:
        X_target (np.ndarray): The image to transfer to.
        y_target (np.ndarray): The label to transfer to.
        X_source (np.ndarray): The image to transfer from.
        y_source (np.ndarray): The label to transfer from.

    Keyword Args:
        min_mix (float=0.333): The minimum mixup coefficient.
        max_mix (float=0.666): The maximum mixup coefficient.
        label_mix (int=0): if
            0 - The labels will be mixed by the weights.\n
            1 - The target label will be used.\n
            2 - The source label will be used.\n
            3 - The max of the labels will be used.\n
            4 - The min of the labels will be used.\n
            5 - The max of the image with the highest weight will be used.\n
            6 - The min of the image with the highest weight will be used.\n
        chance (float=0.5): The chance of mixuping a pixel.
        channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).
    &#34;&#34;&#34;
    if np.random.rand() &gt; chance:
        return X_target, y_target

    x_mixed = X_target.astype(np.float32)
    y_mixed = y_target.astype(np.float32)

    mixup_coeff = np.random.uniform(min_mix, max_mix + 0.001)

    x_mixed = x_mixed * mixup_coeff + X_source * (1 - mixup_coeff)

    if label_mix == 0:
        y_mixed = y_mixed * mixup_coeff + y_source * (1 - mixup_coeff)
    elif label_mix == 1:
        y_mixed = y_target
    elif label_mix == 2:
        y_mixed = y_source
    elif label_mix == 3:
        y_mixed = np.maximum(y_target, y_source)
    elif label_mix == 4:
        y_mixed = np.minimum(y_target, y_source)
    elif label_mix == 5:
        y_mixed = y_target if mixup_coeff &gt;= 0.5 else y_source
    elif label_mix == 6:
        y_mixed = y_target if mixup_coeff &gt;= 0.5 else y_source

    return (
        fit_data_to_dtype(x_mixed, X_target.dtype),
        fit_data_to_dtype(y_mixed, y_target.dtype),
    )</code></pre>
</details>
</dd>
<dt id="buteo.ai.augmentation_funcs.augmentation_noise"><code class="name flex">
<span>def <span class="ident">augmentation_noise</span></span>(<span>X: numpy.ndarray, y: Optional[numpy.ndarray], chance: float = 0.5, max_amount: float = 0.1, additive: bool = False, channel_last: Any = None) -> Tuple[numpy.ndarray, Optional[numpy.ndarray]]</span>
</code></dt>
<dd>
<div class="desc"><p>Adds random noise seperately to each pixel of the image. The noise works
for both channel first and last images.
input should be (height, width, channels) or (channels, height, width).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The image to add noise to.</dd>
</dl>
<p>y (np.ndarray/None): The label to add noise to. If None, no label is returned.
Keyword Args:
chance (float=0.5): The chance of adding noise.
max_amount (float=0.1): The maximum amount of noise to add, sampled uniformly.
additive (bool=False): Whether to add or multiply the noise.
channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).
ignored for this function. Kept to keep the same function signature as other augmentations.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Tuple[np.ndarray, Optional[np.ndarray]]</code></dt>
<dd>The image with noise and optionally the unmodified label.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@jit(nopython=True, nogil=True, cache=True, fastmath=True)
def augmentation_noise(
    X: np.ndarray,
    y: Optional[np.ndarray],
    chance: float = 0.5,
    max_amount: float = 0.1,
    additive: bool = False,
    channel_last: Any = None, # pylint: disable=unused-argument
) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:
    &#34;&#34;&#34;
    Adds random noise seperately to each pixel of the image. The noise works
    for both channel first and last images.
    input should be (height, width, channels) or (channels, height, width).

    Args:
        X (np.ndarray): The image to add noise to.
        y (np.ndarray/None): The label to add noise to. If None, no label is returned.

    Keyword Args:
        chance (float=0.5): The chance of adding noise.
        max_amount (float=0.1): The maximum amount of noise to add, sampled uniformly.
        additive (bool=False): Whether to add or multiply the noise.
        channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).
            ignored for this function. Kept to keep the same function signature as other augmentations.

    Returns:
        Tuple[np.ndarray, Optional[np.ndarray]]: The image with noise and optionally the unmodified label.
    &#34;&#34;&#34;
    if np.random.rand() &gt; chance:
        return X, y

    amount = np.random.rand() * max_amount

    if additive:
        noisy_x = X + np.random.normal(0, amount, X.shape)
    else:
        noisy_x = X * np.random.normal(1, amount, X.shape)

    return fit_data_to_dtype(noisy_x, X.dtype), y</code></pre>
</details>
</dd>
<dt id="buteo.ai.augmentation_funcs.augmentation_rotation"><code class="name flex">
<span>def <span class="ident">augmentation_rotation</span></span>(<span>X: numpy.ndarray, y: Optional[numpy.ndarray], chance: float = 0.5, k: Optional[int] = None, channel_last: bool = True) -> Tuple[numpy.ndarray, Optional[numpy.ndarray]]</span>
</code></dt>
<dd>
<div class="desc"><p>Randomly rotate the image by 90 degrees intervals. Images
can be (channels, height, width) or (height, width, channels).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The image to rotate.</dd>
</dl>
<p>y (np.ndarray/None): The label to rotate.
Keyword Args:
chance (float=0.5): The chance of rotating the image.
k (int=None): The number of 90 degree intervals to rotate by.
channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Tuple[np.ndarray, Optional[np.ndarray]]</code></dt>
<dd>The rotated image and optionally the label.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@jit(nopython=True, nogil=True, cache=True, fastmath=True)
def augmentation_rotation(
    X: np.ndarray,
    y: Optional[np.ndarray],
    chance: float = 0.5,
    k: Optional[int] = None,
    channel_last: bool = True,
) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:
    &#34;&#34;&#34;
    Randomly rotate the image by 90 degrees intervals. Images
    can be (channels, height, width) or (height, width, channels).

    Args:
        X (np.ndarray): The image to rotate.
        y (np.ndarray/None): The label to rotate.

    Keyword Args:
        chance (float=0.5): The chance of rotating the image.
        k (int=None): The number of 90 degree intervals to rotate by.
        channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).

    Returns:
        Tuple[np.ndarray, Optional[np.ndarray]]: The rotated image and optionally the label.
    &#34;&#34;&#34;
    if np.random.rand() &gt; chance or k == 0:
        return X, y

    random_k = np.random.randint(1, 4) if k is None else k
    X_rot = rotate_arr(X, random_k, channel_last)

    if y is None:
        return X_rot, y

    y_rot = rotate_arr(y, random_k, channel_last)

    return X_rot, y_rot</code></pre>
</details>
</dd>
<dt id="buteo.ai.augmentation_funcs.augmentation_sharpen"><code class="name flex">
<span>def <span class="ident">augmentation_sharpen</span></span>(<span>X: numpy.ndarray, y: Optional[numpy.ndarray], chance: float = 0.5, intensity: float = 1.0, apply_to_y: bool = False, channel_last: bool = True) -> Tuple[numpy.ndarray, Optional[numpy.ndarray]]</span>
</code></dt>
<dd>
<div class="desc"><p>Sharpens an image at random.
input should be (height, width, channels) or (channels, height, width).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>The image to potentially sharpen.</dd>
</dl>
<p>y (np.ndarray/None): The label to potentially sharpen. If None, no label is returned.
Keyword Args:
chance (float=0.5): The chance of sharpening a pixel.
intensity (float=1.0): The intensity of the sharpening. from 0.0 to 1.0.
apply_to_y (bool=False): Whether to sharpen the label as well.
channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@jit(nopython=True, nogil=True, cache=True, fastmath=True, parallel=True)
def augmentation_sharpen(
    X: np.ndarray,
    y: Optional[np.ndarray],
    chance: float = 0.5,
    intensity: float = 1.0,
    apply_to_y: bool = False,
    channel_last: bool = True,
) -&gt; Tuple[np.ndarray, Optional[np.ndarray]]:
    &#34;&#34;&#34;
    Sharpens an image at random.
    input should be (height, width, channels) or (channels, height, width).

    Args:
        X (np.ndarray): The image to potentially sharpen.
        y (np.ndarray/None): The label to potentially sharpen. If None, no label is returned.

    Keyword Args:
        chance (float=0.5): The chance of sharpening a pixel.
        intensity (float=1.0): The intensity of the sharpening. from 0.0 to 1.0.
        apply_to_y (bool=False): Whether to sharpen the label as well.
        channel_last (bool=True): Whether the image is (channels, height, width) or (height, width, channels).
    &#34;&#34;&#34;
    if np.random.rand() &gt; chance:
        return X, y

    x_sharpened = X.astype(np.float32)
    y_sharpened = y.astype(np.float32) if y is not None else None

    offsets, weights = simple_unsharp_kernel_2d_3x3()
    channels = X.shape[2] if channel_last else X.shape[0]

    if channel_last:
        for channel in prange(channels):
            x_sharpened[:, :, channel] = convolution_simple(x_sharpened[:, :, channel], offsets, weights, intensity)
            if apply_to_y and y is not None:
                y_sharpened[:, :, channel] = convolution_simple(y_sharpened[:, :, channel], offsets, weights, intensity)
    else:
        for channel in prange(channels):
            x_sharpened[channel, :, :] = convolution_simple(x_sharpened[channel, :, :], offsets, weights, intensity)
            if apply_to_y and y is not None:
                y_sharpened[channel, :, :] = convolution_simple(y_sharpened[channel, :, :], offsets, weights, intensity)

    x_sharpened = fit_data_to_dtype(x_sharpened, X.dtype)
    y_sharpened = fit_data_to_dtype(y_sharpened, y.dtype) if y is not None else None

    return x_sharpened, y_sharpened</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="buteo.ai" href="index.html">buteo.ai</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="buteo.ai.augmentation_funcs.augmentation_blur" href="#buteo.ai.augmentation_funcs.augmentation_blur">augmentation_blur</a></code></li>
<li><code><a title="buteo.ai.augmentation_funcs.augmentation_channel_scale" href="#buteo.ai.augmentation_funcs.augmentation_channel_scale">augmentation_channel_scale</a></code></li>
<li><code><a title="buteo.ai.augmentation_funcs.augmentation_contrast" href="#buteo.ai.augmentation_funcs.augmentation_contrast">augmentation_contrast</a></code></li>
<li><code><a title="buteo.ai.augmentation_funcs.augmentation_cutmix" href="#buteo.ai.augmentation_funcs.augmentation_cutmix">augmentation_cutmix</a></code></li>
<li><code><a title="buteo.ai.augmentation_funcs.augmentation_drop_channel" href="#buteo.ai.augmentation_funcs.augmentation_drop_channel">augmentation_drop_channel</a></code></li>
<li><code><a title="buteo.ai.augmentation_funcs.augmentation_drop_pixel" href="#buteo.ai.augmentation_funcs.augmentation_drop_pixel">augmentation_drop_pixel</a></code></li>
<li><code><a title="buteo.ai.augmentation_funcs.augmentation_mirror" href="#buteo.ai.augmentation_funcs.augmentation_mirror">augmentation_mirror</a></code></li>
<li><code><a title="buteo.ai.augmentation_funcs.augmentation_misalign_pixels" href="#buteo.ai.augmentation_funcs.augmentation_misalign_pixels">augmentation_misalign_pixels</a></code></li>
<li><code><a title="buteo.ai.augmentation_funcs.augmentation_mixup" href="#buteo.ai.augmentation_funcs.augmentation_mixup">augmentation_mixup</a></code></li>
<li><code><a title="buteo.ai.augmentation_funcs.augmentation_noise" href="#buteo.ai.augmentation_funcs.augmentation_noise">augmentation_noise</a></code></li>
<li><code><a title="buteo.ai.augmentation_funcs.augmentation_rotation" href="#buteo.ai.augmentation_funcs.augmentation_rotation">augmentation_rotation</a></code></li>
<li><code><a title="buteo.ai.augmentation_funcs.augmentation_sharpen" href="#buteo.ai.augmentation_funcs.augmentation_sharpen">augmentation_sharpen</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.1</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>