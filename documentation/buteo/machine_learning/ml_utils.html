<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>buteo.machine_learning.ml_utils API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>buteo.machine_learning.ml_utils</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import math
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.layers import Activation
from tensorflow.keras.utils import get_custom_objects


# TODO: Remove SKlearn


def create_step_decay(learning_rate=0.001, drop_rate=0.5, epochs_per_drop=10):
    def step_decay(epoch):
        initial_lrate = learning_rate
        drop = drop_rate
        epochs_drop = epochs_per_drop
        lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))
        return lrate

    return step_decay


def count_freq(arr: np.ndarray) -&gt; np.ndarray:
    bins = np.bincount(arr)
    classes = np.nonzero(bins)[0]
    return np.vstack([classes, bins[classes]]).T


# Printing visuals
def pad(s, dl, dr):
    split = s.split(&#34;.&#34;)
    left = split[0]
    right = split[1]

    if len(left) &lt; dl:
        left = ((dl - len(left)) * &#34; &#34;) + left

    if len(right) &lt; dr:
        right = right + ((dr - len(right)) * &#34;0&#34;)

    return left + &#34;.&#34; + right


# https://stackoverflow.com/a/44233061/8564588
def minority_class_mask(arr, minority):
    return np.hstack(
        [
            np.random.choice(np.where(arr == l)[0], minority, replace=False)
            for l in np.unique(arr)
        ]
    )


def create_submask(arr, amount):
    z = np.zeros(len(arr) - int(amount), &#34;bool&#34;)
    m = np.ones(amount, &#34;bool&#34;)
    a = np.concatenate([z, m])
    np.random.shuffle(a)

    return a


def add_rotations(X, k=4, axes=(1, 2)):
    if k == 1:
        return X
    elif k == 2:
        return np.concatenate(
            [
                X,
                np.rot90(X, k=2, axes=axes),
            ]
        )
    elif k == 3:
        return np.concatenate(
            [
                X,
                np.rot90(X, k=1, axes=axes),
                np.rot90(X, k=2, axes=axes),
            ]
        )
    else:
        return np.concatenate(
            [
                X,
                np.rot90(X, k=1, axes=axes),
                np.rot90(X, k=2, axes=axes),
                np.rot90(X, k=3, axes=axes),
            ]
        )


def add_noise(X, amount=0.01):
    return X * np.random.normal(1, amount, X.shape)


def add_fixed_noise(X, center=0, amount=0.05):
    return X + np.random.normal(center, amount, X.shape)


def scale_to_01(X):
    return (X - X.min()) / (X.max() - X.min())


# stratify a regression split
def train_split_mask_regression(y, split=0.3, stratified=True):
    from sklearn.model_selection import train_test_split

    if stratified is True:
        strats = np.digitize(y, np.percentile(y, [10, 20, 30, 40, 50, 60, 70, 80, 90]))
        indices = np.arange(0, len(strats), 1)

        _X_train, _X_test, y_train, y_test = train_test_split(
            indices, strats, stratify=strats, test_size=split
        )

        return (y_train, y_test)

    split_amount = int(round(len(y) * split))

    positive = np.full(len(y) - split_amount, True)
    negative = np.full(split_amount, False)
    merged = np.append(positive, negative)
    np.random.shuffle(merged)

    return (merged, ~merged)


def add_randomness(arr):
    flips = int(round(len(arr) / 4))
    return np.concatenate(
        [
            arr[0:flips],
            np.rot90(arr[flips : 2 * flips], k=1, axes=(1, 2)),
            np.rot90(arr[flips * 2 : flips * 3], k=2, axes=(1, 2)),
            np.rot90(arr[flips * 3 :], k=3, axes=(1, 2)),
        ]
    )


def histogram_selection(
    y, zero_class=True, resolution=5, outliers=True, allow_gap=0.2, whisk_range=1.5
):

    indices = np.arange(0, len(y), 1)

    if outliers is True:
        if zero_class is True:
            q1 = np.quantile(y[y &gt; 0], 0.25)
            q3 = np.quantile(y[y &gt; 0], 0.75)
        else:
            q1 = np.quantile(y, 0.25)
            q3 = np.quantile(y, 0.75)
        iqr = q3 - q1
        whisk = iqr * whisk_range

        cl_start = q1 - whisk
        cl_end = q3 + whisk
        step_size = (cl_end - cl_start) / resolution
    else:
        step_size = (y.max() - y.min()) / resolution
        cl_start = step_size
        cl_end = y.max()

    if zero_class is True:
        classes = np.digitize(
            y, np.arange(0, cl_end + step_size, step_size), right=True
        )
    else:
        classes = np.digitize(
            y, np.arange(step_size, cl_end + step_size, step_size), right=True
        )

    frequency = count_freq(classes)
    minority = frequency.min(axis=0)[1]
    max_samples = int(round(minority * (1 + allow_gap)))

    samples = []

    for hist_class in np.unique(classes):
        sample_count = len(classes[classes == hist_class])
        if sample_count &gt; max_samples:
            samples.append(
                np.random.choice(
                    indices[classes == hist_class], max_samples, replace=False
                )
            )
        else:
            samples.append(
                np.random.choice(
                    indices[classes == hist_class], sample_count, replace=False
                )
            )

    return np.hstack(samples)


def test_correlation(df: pd.DataFrame, cutoff: float = 0.75) -&gt; np.ndarray:
    abs_corr = df.corr().abs()
    triangle = np.array(np.triu(np.ones(abs_corr.shape), k=1), dtype=np.bool)
    upper_tri = abs_corr.where(triangle)
    to_drop = [
        column for column in upper_tri.columns if any(upper_tri[column] &gt; cutoff)
    ]
    return to_drop


def mish(inputs):
    return inputs * tf.math.tanh(tf.math.softplus(inputs))


class Mish(Activation):
    &#34;&#34;&#34;
    Mish Activation Function.
    .. math::
        mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + e^{x}))
    Shape:
        - Input: Arbitrary. Use the keyword argument `input_shape`
        (tuple of integers, does not include the samples axis)
        when using this layer as the first layer in a model.
        - Output: Same shape as the input.
    Examples:
        &gt;&gt;&gt; X = Activation(&#39;Mish&#39;, name=&#34;conv1_act&#34;)(X_input)
    &#34;&#34;&#34;

    def __init__(self, activation, **kwargs):
        super(Mish, self).__init__(activation, **kwargs)
        self.__name__ = &#34;Mish&#34;


def load_mish():
    get_custom_objects().update({&#34;Mish&#34;: Mish(mish)})


def mad_standard(arr):
    median = np.median(arr)
    absdev = np.abs(np.subtract(arr, median))
    madstd = np.median(absdev) * 1.4826

    return ((arr - median) / madstd).astype(&#34;float32&#34;)


def iqr_scale(arr):
    q1, median, q3 = np.percentile(arr, [25, 50, 75])

    return ((arr - median) / (q3 - q1)).astype(&#34;float32&#34;)


def mean_standard(arr):
    mean = np.mean(arr)
    std = np.std(arr)

    return ((arr - mean) / std).astype(&#34;float32&#34;)


def min_max(arr):
    return (arr / arr.max()).astype(&#34;float32&#34;)


def trunc_scale(arr, val):
    return (np.where(arr &gt; val, val, arr) / val).astype(&#34;float32&#34;)


def scale_percentile(arr, percentile=98):
    percentile = np.percentile(arr, percentile)

    truncated = np.where(arr &gt; percentile, percentile, arr)

    return (truncated / truncated.max()).astype(&#34;float32&#34;)


# np.set_printoptions(suppress=True)
def preprocess_optical(
    arr, cutoff_low=0, cutoff_high=8000, target_low=0, target_high=1
):
    clipped = np.where(
        arr &gt; cutoff_high, cutoff_high, np.where(arr &lt; cutoff_low, cutoff_low, arr)
    )
    val_a = (target_high - target_low) / (cutoff_high - cutoff_low)
    val_b = target_high - (val_a * cutoff_high)

    return ((val_a * clipped) + val_b).astype(&#34;float32&#34;)


def preprocess_coh(arr, target_low=0, target_high=1):
    return preprocess_optical(arr, 0, 1, target_low, target_high)


def get_offsets(size):
    high_mid = size // 2
    high_low = high_mid // 2
    high_high = high_mid + high_low

    return [
        [0, 0],
        [0, high_low],
        [0, high_mid],
        [0, high_high],
        [high_low, high_low],
        [high_mid, high_mid],
        [high_high, high_high],
        [high_low, 0],
        [high_mid, 0],
        [high_high, 0],
    ]


# Converts to decibel, thresholds between -30db and 10db and scales to -1 to 1
def preprocess_sar(
    arr, convert_db=True, cutoff_low=-30, cutoff_high=15, target_low=0, target_high=1
):
    if convert_db:
        with np.errstate(divide=&#34;ignore&#34;, invalid=&#34;ignore&#34;):
            arr_adj = 10 * np.where(arr != 0, np.log10(arr), cutoff_low)
    else:
        arr_adj = arr

    thresholded = np.where(
        arr_adj &gt; cutoff_high,
        cutoff_high,
        np.where(arr_adj &lt; cutoff_low, cutoff_low, arr_adj),
    )

    scaled = preprocess_optical(
        thresholded,
        cutoff_low=cutoff_low,
        cutoff_high=cutoff_high,
        target_low=target_low,
        target_high=target_high,
    )

    return scaled


def mse(y_pred, y_true):
    y_pred = tf.cast(y_pred, tf.float64)
    y_true = tf.cast(y_true, tf.float64)

    return tf.math.reduce_mean(tf.math.squared_difference(y_pred, y_true))


def mse_sumbias(y_pred, y_true, bias=0.5):
    _mse = tf.math.reduce_mean(tf.math.squared_difference(y_pred, y_true))
    _tpe = tf.math.abs(tf.math.reduce_sum(y_pred) - tf.math.reduce_sum(y_true))
    tpe_biased = tf.math.pow(_tpe, bias)

    return _mse + tpe_biased


def mse_biased(y_pred, y_true):
    y_pred = tf.cast(y_pred, tf.float32)
    y_true = tf.cast(y_true, tf.float32)
    bias = tf.cast(1.50, tf.float32)

    greater_one = tf.cast(tf.math.greater(y_true, y_pred), tf.float32)
    greater_two = tf.cast(tf.math.greater_equal(y_pred, y_true), tf.float32)

    # scale = (greater_one * bias) + greater_two
    scale = (greater_two * bias) + greater_one

    sqr_diff = ((y_pred - y_true) * scale) ** 2

    return tf.math.reduce_mean(sqr_diff)


def log_cosh(y_pred, y_true):
    y_pred = tf.cast(y_pred, tf.float64)
    y_true = tf.cast(y_true, tf.float64)

    y_pred = tf.nn.relu(y_pred)

    return tf.losses.log_cosh(y_true, y_pred)


def tpe(y_true, y_pred):
    y_pred = tf.cast(y_pred, tf.float64)
    y_true = tf.cast(y_true, tf.float64)

    espilon = 1e-7
    pred_sum = tf.math.reduce_sum(y_pred)
    true_sum = tf.math.reduce_sum(y_true)
    sdif = pred_sum - true_sum
    part = (sdif / (true_sum + espilon)) * 100
    clipped = tf.clip_by_value(part, -100.0, 100.0)

    return clipped


class SaveBestModel(tf.keras.callbacks.Callback):
    def __init__(self, save_best_metric=&#34;val_loss&#34;, this_max=False):
        self.save_best_metric = save_best_metric
        self.max = this_max
        if this_max:
            self.best = float(&#34;-inf&#34;)
        else:
            self.best = float(&#34;inf&#34;)

    def on_epoch_end(self, epoch, logs=None):
        metric_value = abs(logs[self.save_best_metric])
        if self.max:
            if metric_value &gt; self.best:
                self.best = metric_value
                self.best_weights = self.model.get_weights()

        else:
            if metric_value &lt; self.best:
                self.best = metric_value
                self.best_weights = self.model.get_weights()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="buteo.machine_learning.ml_utils.add_fixed_noise"><code class="name flex">
<span>def <span class="ident">add_fixed_noise</span></span>(<span>X, center=0, amount=0.05)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_fixed_noise(X, center=0, amount=0.05):
    return X + np.random.normal(center, amount, X.shape)</code></pre>
</details>
</dd>
<dt id="buteo.machine_learning.ml_utils.add_noise"><code class="name flex">
<span>def <span class="ident">add_noise</span></span>(<span>X, amount=0.01)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_noise(X, amount=0.01):
    return X * np.random.normal(1, amount, X.shape)</code></pre>
</details>
</dd>
<dt id="buteo.machine_learning.ml_utils.add_randomness"><code class="name flex">
<span>def <span class="ident">add_randomness</span></span>(<span>arr)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_randomness(arr):
    flips = int(round(len(arr) / 4))
    return np.concatenate(
        [
            arr[0:flips],
            np.rot90(arr[flips : 2 * flips], k=1, axes=(1, 2)),
            np.rot90(arr[flips * 2 : flips * 3], k=2, axes=(1, 2)),
            np.rot90(arr[flips * 3 :], k=3, axes=(1, 2)),
        ]
    )</code></pre>
</details>
</dd>
<dt id="buteo.machine_learning.ml_utils.add_rotations"><code class="name flex">
<span>def <span class="ident">add_rotations</span></span>(<span>X, k=4, axes=(1, 2))</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def add_rotations(X, k=4, axes=(1, 2)):
    if k == 1:
        return X
    elif k == 2:
        return np.concatenate(
            [
                X,
                np.rot90(X, k=2, axes=axes),
            ]
        )
    elif k == 3:
        return np.concatenate(
            [
                X,
                np.rot90(X, k=1, axes=axes),
                np.rot90(X, k=2, axes=axes),
            ]
        )
    else:
        return np.concatenate(
            [
                X,
                np.rot90(X, k=1, axes=axes),
                np.rot90(X, k=2, axes=axes),
                np.rot90(X, k=3, axes=axes),
            ]
        )</code></pre>
</details>
</dd>
<dt id="buteo.machine_learning.ml_utils.count_freq"><code class="name flex">
<span>def <span class="ident">count_freq</span></span>(<span>arr: numpy.ndarray) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def count_freq(arr: np.ndarray) -&gt; np.ndarray:
    bins = np.bincount(arr)
    classes = np.nonzero(bins)[0]
    return np.vstack([classes, bins[classes]]).T</code></pre>
</details>
</dd>
<dt id="buteo.machine_learning.ml_utils.create_step_decay"><code class="name flex">
<span>def <span class="ident">create_step_decay</span></span>(<span>learning_rate=0.001, drop_rate=0.5, epochs_per_drop=10)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_step_decay(learning_rate=0.001, drop_rate=0.5, epochs_per_drop=10):
    def step_decay(epoch):
        initial_lrate = learning_rate
        drop = drop_rate
        epochs_drop = epochs_per_drop
        lrate = initial_lrate * math.pow(drop, math.floor((1 + epoch) / epochs_drop))
        return lrate

    return step_decay</code></pre>
</details>
</dd>
<dt id="buteo.machine_learning.ml_utils.create_submask"><code class="name flex">
<span>def <span class="ident">create_submask</span></span>(<span>arr, amount)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_submask(arr, amount):
    z = np.zeros(len(arr) - int(amount), &#34;bool&#34;)
    m = np.ones(amount, &#34;bool&#34;)
    a = np.concatenate([z, m])
    np.random.shuffle(a)

    return a</code></pre>
</details>
</dd>
<dt id="buteo.machine_learning.ml_utils.get_offsets"><code class="name flex">
<span>def <span class="ident">get_offsets</span></span>(<span>size)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_offsets(size):
    high_mid = size // 2
    high_low = high_mid // 2
    high_high = high_mid + high_low

    return [
        [0, 0],
        [0, high_low],
        [0, high_mid],
        [0, high_high],
        [high_low, high_low],
        [high_mid, high_mid],
        [high_high, high_high],
        [high_low, 0],
        [high_mid, 0],
        [high_high, 0],
    ]</code></pre>
</details>
</dd>
<dt id="buteo.machine_learning.ml_utils.histogram_selection"><code class="name flex">
<span>def <span class="ident">histogram_selection</span></span>(<span>y, zero_class=True, resolution=5, outliers=True, allow_gap=0.2, whisk_range=1.5)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def histogram_selection(
    y, zero_class=True, resolution=5, outliers=True, allow_gap=0.2, whisk_range=1.5
):

    indices = np.arange(0, len(y), 1)

    if outliers is True:
        if zero_class is True:
            q1 = np.quantile(y[y &gt; 0], 0.25)
            q3 = np.quantile(y[y &gt; 0], 0.75)
        else:
            q1 = np.quantile(y, 0.25)
            q3 = np.quantile(y, 0.75)
        iqr = q3 - q1
        whisk = iqr * whisk_range

        cl_start = q1 - whisk
        cl_end = q3 + whisk
        step_size = (cl_end - cl_start) / resolution
    else:
        step_size = (y.max() - y.min()) / resolution
        cl_start = step_size
        cl_end = y.max()

    if zero_class is True:
        classes = np.digitize(
            y, np.arange(0, cl_end + step_size, step_size), right=True
        )
    else:
        classes = np.digitize(
            y, np.arange(step_size, cl_end + step_size, step_size), right=True
        )

    frequency = count_freq(classes)
    minority = frequency.min(axis=0)[1]
    max_samples = int(round(minority * (1 + allow_gap)))

    samples = []

    for hist_class in np.unique(classes):
        sample_count = len(classes[classes == hist_class])
        if sample_count &gt; max_samples:
            samples.append(
                np.random.choice(
                    indices[classes == hist_class], max_samples, replace=False
                )
            )
        else:
            samples.append(
                np.random.choice(
                    indices[classes == hist_class], sample_count, replace=False
                )
            )

    return np.hstack(samples)</code></pre>
</details>
</dd>
<dt id="buteo.machine_learning.ml_utils.iqr_scale"><code class="name flex">
<span>def <span class="ident">iqr_scale</span></span>(<span>arr)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def iqr_scale(arr):
    q1, median, q3 = np.percentile(arr, [25, 50, 75])

    return ((arr - median) / (q3 - q1)).astype(&#34;float32&#34;)</code></pre>
</details>
</dd>
<dt id="buteo.machine_learning.ml_utils.load_mish"><code class="name flex">
<span>def <span class="ident">load_mish</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_mish():
    get_custom_objects().update({&#34;Mish&#34;: Mish(mish)})</code></pre>
</details>
</dd>
<dt id="buteo.machine_learning.ml_utils.log_cosh"><code class="name flex">
<span>def <span class="ident">log_cosh</span></span>(<span>y_pred, y_true)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def log_cosh(y_pred, y_true):
    y_pred = tf.cast(y_pred, tf.float64)
    y_true = tf.cast(y_true, tf.float64)

    y_pred = tf.nn.relu(y_pred)

    return tf.losses.log_cosh(y_true, y_pred)</code></pre>
</details>
</dd>
<dt id="buteo.machine_learning.ml_utils.mad_standard"><code class="name flex">
<span>def <span class="ident">mad_standard</span></span>(<span>arr)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mad_standard(arr):
    median = np.median(arr)
    absdev = np.abs(np.subtract(arr, median))
    madstd = np.median(absdev) * 1.4826

    return ((arr - median) / madstd).astype(&#34;float32&#34;)</code></pre>
</details>
</dd>
<dt id="buteo.machine_learning.ml_utils.mean_standard"><code class="name flex">
<span>def <span class="ident">mean_standard</span></span>(<span>arr)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mean_standard(arr):
    mean = np.mean(arr)
    std = np.std(arr)

    return ((arr - mean) / std).astype(&#34;float32&#34;)</code></pre>
</details>
</dd>
<dt id="buteo.machine_learning.ml_utils.min_max"><code class="name flex">
<span>def <span class="ident">min_max</span></span>(<span>arr)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def min_max(arr):
    return (arr / arr.max()).astype(&#34;float32&#34;)</code></pre>
</details>
</dd>
<dt id="buteo.machine_learning.ml_utils.minority_class_mask"><code class="name flex">
<span>def <span class="ident">minority_class_mask</span></span>(<span>arr, minority)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def minority_class_mask(arr, minority):
    return np.hstack(
        [
            np.random.choice(np.where(arr == l)[0], minority, replace=False)
            for l in np.unique(arr)
        ]
    )</code></pre>
</details>
</dd>
<dt id="buteo.machine_learning.ml_utils.mish"><code class="name flex">
<span>def <span class="ident">mish</span></span>(<span>inputs)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mish(inputs):
    return inputs * tf.math.tanh(tf.math.softplus(inputs))</code></pre>
</details>
</dd>
<dt id="buteo.machine_learning.ml_utils.mse"><code class="name flex">
<span>def <span class="ident">mse</span></span>(<span>y_pred, y_true)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mse(y_pred, y_true):
    y_pred = tf.cast(y_pred, tf.float64)
    y_true = tf.cast(y_true, tf.float64)

    return tf.math.reduce_mean(tf.math.squared_difference(y_pred, y_true))</code></pre>
</details>
</dd>
<dt id="buteo.machine_learning.ml_utils.mse_biased"><code class="name flex">
<span>def <span class="ident">mse_biased</span></span>(<span>y_pred, y_true)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mse_biased(y_pred, y_true):
    y_pred = tf.cast(y_pred, tf.float32)
    y_true = tf.cast(y_true, tf.float32)
    bias = tf.cast(1.50, tf.float32)

    greater_one = tf.cast(tf.math.greater(y_true, y_pred), tf.float32)
    greater_two = tf.cast(tf.math.greater_equal(y_pred, y_true), tf.float32)

    # scale = (greater_one * bias) + greater_two
    scale = (greater_two * bias) + greater_one

    sqr_diff = ((y_pred - y_true) * scale) ** 2

    return tf.math.reduce_mean(sqr_diff)</code></pre>
</details>
</dd>
<dt id="buteo.machine_learning.ml_utils.mse_sumbias"><code class="name flex">
<span>def <span class="ident">mse_sumbias</span></span>(<span>y_pred, y_true, bias=0.5)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mse_sumbias(y_pred, y_true, bias=0.5):
    _mse = tf.math.reduce_mean(tf.math.squared_difference(y_pred, y_true))
    _tpe = tf.math.abs(tf.math.reduce_sum(y_pred) - tf.math.reduce_sum(y_true))
    tpe_biased = tf.math.pow(_tpe, bias)

    return _mse + tpe_biased</code></pre>
</details>
</dd>
<dt id="buteo.machine_learning.ml_utils.pad"><code class="name flex">
<span>def <span class="ident">pad</span></span>(<span>s, dl, dr)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pad(s, dl, dr):
    split = s.split(&#34;.&#34;)
    left = split[0]
    right = split[1]

    if len(left) &lt; dl:
        left = ((dl - len(left)) * &#34; &#34;) + left

    if len(right) &lt; dr:
        right = right + ((dr - len(right)) * &#34;0&#34;)

    return left + &#34;.&#34; + right</code></pre>
</details>
</dd>
<dt id="buteo.machine_learning.ml_utils.preprocess_coh"><code class="name flex">
<span>def <span class="ident">preprocess_coh</span></span>(<span>arr, target_low=0, target_high=1)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def preprocess_coh(arr, target_low=0, target_high=1):
    return preprocess_optical(arr, 0, 1, target_low, target_high)</code></pre>
</details>
</dd>
<dt id="buteo.machine_learning.ml_utils.preprocess_optical"><code class="name flex">
<span>def <span class="ident">preprocess_optical</span></span>(<span>arr, cutoff_low=0, cutoff_high=8000, target_low=0, target_high=1)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def preprocess_optical(
    arr, cutoff_low=0, cutoff_high=8000, target_low=0, target_high=1
):
    clipped = np.where(
        arr &gt; cutoff_high, cutoff_high, np.where(arr &lt; cutoff_low, cutoff_low, arr)
    )
    val_a = (target_high - target_low) / (cutoff_high - cutoff_low)
    val_b = target_high - (val_a * cutoff_high)

    return ((val_a * clipped) + val_b).astype(&#34;float32&#34;)</code></pre>
</details>
</dd>
<dt id="buteo.machine_learning.ml_utils.preprocess_sar"><code class="name flex">
<span>def <span class="ident">preprocess_sar</span></span>(<span>arr, convert_db=True, cutoff_low=-30, cutoff_high=15, target_low=0, target_high=1)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def preprocess_sar(
    arr, convert_db=True, cutoff_low=-30, cutoff_high=15, target_low=0, target_high=1
):
    if convert_db:
        with np.errstate(divide=&#34;ignore&#34;, invalid=&#34;ignore&#34;):
            arr_adj = 10 * np.where(arr != 0, np.log10(arr), cutoff_low)
    else:
        arr_adj = arr

    thresholded = np.where(
        arr_adj &gt; cutoff_high,
        cutoff_high,
        np.where(arr_adj &lt; cutoff_low, cutoff_low, arr_adj),
    )

    scaled = preprocess_optical(
        thresholded,
        cutoff_low=cutoff_low,
        cutoff_high=cutoff_high,
        target_low=target_low,
        target_high=target_high,
    )

    return scaled</code></pre>
</details>
</dd>
<dt id="buteo.machine_learning.ml_utils.scale_percentile"><code class="name flex">
<span>def <span class="ident">scale_percentile</span></span>(<span>arr, percentile=98)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def scale_percentile(arr, percentile=98):
    percentile = np.percentile(arr, percentile)

    truncated = np.where(arr &gt; percentile, percentile, arr)

    return (truncated / truncated.max()).astype(&#34;float32&#34;)</code></pre>
</details>
</dd>
<dt id="buteo.machine_learning.ml_utils.scale_to_01"><code class="name flex">
<span>def <span class="ident">scale_to_01</span></span>(<span>X)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def scale_to_01(X):
    return (X - X.min()) / (X.max() - X.min())</code></pre>
</details>
</dd>
<dt id="buteo.machine_learning.ml_utils.test_correlation"><code class="name flex">
<span>def <span class="ident">test_correlation</span></span>(<span>df: pandas.core.frame.DataFrame, cutoff: float = 0.75) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_correlation(df: pd.DataFrame, cutoff: float = 0.75) -&gt; np.ndarray:
    abs_corr = df.corr().abs()
    triangle = np.array(np.triu(np.ones(abs_corr.shape), k=1), dtype=np.bool)
    upper_tri = abs_corr.where(triangle)
    to_drop = [
        column for column in upper_tri.columns if any(upper_tri[column] &gt; cutoff)
    ]
    return to_drop</code></pre>
</details>
</dd>
<dt id="buteo.machine_learning.ml_utils.tpe"><code class="name flex">
<span>def <span class="ident">tpe</span></span>(<span>y_true, y_pred)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tpe(y_true, y_pred):
    y_pred = tf.cast(y_pred, tf.float64)
    y_true = tf.cast(y_true, tf.float64)

    espilon = 1e-7
    pred_sum = tf.math.reduce_sum(y_pred)
    true_sum = tf.math.reduce_sum(y_true)
    sdif = pred_sum - true_sum
    part = (sdif / (true_sum + espilon)) * 100
    clipped = tf.clip_by_value(part, -100.0, 100.0)

    return clipped</code></pre>
</details>
</dd>
<dt id="buteo.machine_learning.ml_utils.train_split_mask_regression"><code class="name flex">
<span>def <span class="ident">train_split_mask_regression</span></span>(<span>y, split=0.3, stratified=True)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train_split_mask_regression(y, split=0.3, stratified=True):
    from sklearn.model_selection import train_test_split

    if stratified is True:
        strats = np.digitize(y, np.percentile(y, [10, 20, 30, 40, 50, 60, 70, 80, 90]))
        indices = np.arange(0, len(strats), 1)

        _X_train, _X_test, y_train, y_test = train_test_split(
            indices, strats, stratify=strats, test_size=split
        )

        return (y_train, y_test)

    split_amount = int(round(len(y) * split))

    positive = np.full(len(y) - split_amount, True)
    negative = np.full(split_amount, False)
    merged = np.append(positive, negative)
    np.random.shuffle(merged)

    return (merged, ~merged)</code></pre>
</details>
</dd>
<dt id="buteo.machine_learning.ml_utils.trunc_scale"><code class="name flex">
<span>def <span class="ident">trunc_scale</span></span>(<span>arr, val)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def trunc_scale(arr, val):
    return (np.where(arr &gt; val, val, arr) / val).astype(&#34;float32&#34;)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="buteo.machine_learning.ml_utils.Mish"><code class="flex name class">
<span>class <span class="ident">Mish</span></span>
<span>(</span><span>activation, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Mish Activation Function.
[ mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + e^{x})) ]</p>
<h2 id="shape">Shape</h2>
<ul>
<li>Input: Arbitrary. Use the keyword argument <code>input_shape</code>
(tuple of integers, does not include the samples axis)
when using this layer as the first layer in a model.</li>
<li>Output: Same shape as the input.</li>
</ul>
<h2 id="examples">Examples</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; X = Activation('Mish', name=&quot;conv1_act&quot;)(X_input)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Mish(Activation):
    &#34;&#34;&#34;
    Mish Activation Function.
    .. math::
        mish(x) = x * tanh(softplus(x)) = x * tanh(ln(1 + e^{x}))
    Shape:
        - Input: Arbitrary. Use the keyword argument `input_shape`
        (tuple of integers, does not include the samples axis)
        when using this layer as the first layer in a model.
        - Output: Same shape as the input.
    Examples:
        &gt;&gt;&gt; X = Activation(&#39;Mish&#39;, name=&#34;conv1_act&#34;)(X_input)
    &#34;&#34;&#34;

    def __init__(self, activation, **kwargs):
        super(Mish, self).__init__(activation, **kwargs)
        self.__name__ = &#34;Mish&#34;</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>keras.layers.core.activation.Activation</li>
<li>keras.engine.base_layer.Layer</li>
<li>tensorflow.python.module.module.Module</li>
<li>tensorflow.python.training.tracking.tracking.AutoTrackable</li>
<li>tensorflow.python.training.tracking.base.Trackable</li>
<li>keras.utils.version_utils.LayerVersionSelector</li>
</ul>
</dd>
<dt id="buteo.machine_learning.ml_utils.SaveBestModel"><code class="flex name class">
<span>class <span class="ident">SaveBestModel</span></span>
<span>(</span><span>save_best_metric='val_loss', this_max=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Abstract base class used to build new callbacks.</p>
<p>Callbacks can be passed to keras methods such as <code>fit</code>, <code>evaluate</code>, and
<code>predict</code> in order to hook into the various stages of the model training and
inference lifecycle.</p>
<p>To create a custom callback, subclass <code>keras.callbacks.Callback</code> and override
the method associated with the stage of interest. See
<a href="https://www.tensorflow.org/guide/keras/custom_callback">https://www.tensorflow.org/guide/keras/custom_callback</a> for more information.</p>
<p>Example:</p>
<pre><code class="language-python-repl">&gt;&gt;&gt; training_finished = False
&gt;&gt;&gt; class MyCallback(tf.keras.callbacks.Callback):
...   def on_train_end(self, logs=None):
...     global training_finished
...     training_finished = True
&gt;&gt;&gt; model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))])
&gt;&gt;&gt; model.compile(loss='mean_squared_error')
&gt;&gt;&gt; model.fit(tf.constant([[1.0]]), tf.constant([[1.0]]),
...           callbacks=[MyCallback()])
&gt;&gt;&gt; assert training_finished == True
</code></pre>
<p>If you want to use <code>Callback</code> objects in a custom training loop:</p>
<ol>
<li>You should pack all your callbacks into a single <code>callbacks.CallbackList</code>
so they can all be called together.</li>
<li>You will need to manually call all the <code>on_*</code> methods at the apropriate
locations in your loop. Like this:</li>
</ol>
<p>```
callbacks =
tf.keras.callbacks.CallbackList([&hellip;])
callbacks.append(&hellip;)</p>
<p>callbacks.on_train_begin(&hellip;)
for epoch in range(EPOCHS):
callbacks.on_epoch_begin(epoch)
for i, data in dataset.enumerate():
callbacks.on_train_batch_begin(i)
batch_logs = model.train_step(data)
callbacks.on_train_batch_end(i, batch_logs)
epoch_logs = &hellip;
callbacks.on_epoch_end(epoch, epoch_logs)
final_logs=&hellip;
callbacks.on_train_end(final_logs)
```</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>params</code></strong></dt>
<dd>Dict. Training parameters
(eg. verbosity, batch size, number of epochs&hellip;).</dd>
<dt><strong><code>model</code></strong></dt>
<dd>Instance of <code>keras.models.Model</code>.
Reference of the model being trained.</dd>
</dl>
<p>The <code>logs</code> dictionary that callback methods
take as argument will contain keys for quantities relevant to
the current batch or epoch (see method-specific docstrings).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SaveBestModel(tf.keras.callbacks.Callback):
    def __init__(self, save_best_metric=&#34;val_loss&#34;, this_max=False):
        self.save_best_metric = save_best_metric
        self.max = this_max
        if this_max:
            self.best = float(&#34;-inf&#34;)
        else:
            self.best = float(&#34;inf&#34;)

    def on_epoch_end(self, epoch, logs=None):
        metric_value = abs(logs[self.save_best_metric])
        if self.max:
            if metric_value &gt; self.best:
                self.best = metric_value
                self.best_weights = self.model.get_weights()

        else:
            if metric_value &lt; self.best:
                self.best = metric_value
                self.best_weights = self.model.get_weights()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>keras.callbacks.Callback</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="buteo.machine_learning.ml_utils.SaveBestModel.on_epoch_end"><code class="name flex">
<span>def <span class="ident">on_epoch_end</span></span>(<span>self, epoch, logs=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Called at the end of an epoch.</p>
<p>Subclasses should override for any actions to run. This function should only
be called during TRAIN mode.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>epoch</code></strong></dt>
<dd>Integer, index of epoch.</dd>
<dt><strong><code>logs</code></strong></dt>
<dd>Dict, metric results for this training epoch, and for the
validation epoch if validation is performed. Validation result keys
are prefixed with <code>val_</code>. For training epoch, the values of the</dd>
</dl>
<p><code>Model</code>'s metrics are returned. Example : <code>{'loss': 0.2, 'accuracy':
0.7}</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def on_epoch_end(self, epoch, logs=None):
    metric_value = abs(logs[self.save_best_metric])
    if self.max:
        if metric_value &gt; self.best:
            self.best = metric_value
            self.best_weights = self.model.get_weights()

    else:
        if metric_value &lt; self.best:
            self.best = metric_value
            self.best_weights = self.model.get_weights()</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="buteo.machine_learning" href="index.html">buteo.machine_learning</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="buteo.machine_learning.ml_utils.add_fixed_noise" href="#buteo.machine_learning.ml_utils.add_fixed_noise">add_fixed_noise</a></code></li>
<li><code><a title="buteo.machine_learning.ml_utils.add_noise" href="#buteo.machine_learning.ml_utils.add_noise">add_noise</a></code></li>
<li><code><a title="buteo.machine_learning.ml_utils.add_randomness" href="#buteo.machine_learning.ml_utils.add_randomness">add_randomness</a></code></li>
<li><code><a title="buteo.machine_learning.ml_utils.add_rotations" href="#buteo.machine_learning.ml_utils.add_rotations">add_rotations</a></code></li>
<li><code><a title="buteo.machine_learning.ml_utils.count_freq" href="#buteo.machine_learning.ml_utils.count_freq">count_freq</a></code></li>
<li><code><a title="buteo.machine_learning.ml_utils.create_step_decay" href="#buteo.machine_learning.ml_utils.create_step_decay">create_step_decay</a></code></li>
<li><code><a title="buteo.machine_learning.ml_utils.create_submask" href="#buteo.machine_learning.ml_utils.create_submask">create_submask</a></code></li>
<li><code><a title="buteo.machine_learning.ml_utils.get_offsets" href="#buteo.machine_learning.ml_utils.get_offsets">get_offsets</a></code></li>
<li><code><a title="buteo.machine_learning.ml_utils.histogram_selection" href="#buteo.machine_learning.ml_utils.histogram_selection">histogram_selection</a></code></li>
<li><code><a title="buteo.machine_learning.ml_utils.iqr_scale" href="#buteo.machine_learning.ml_utils.iqr_scale">iqr_scale</a></code></li>
<li><code><a title="buteo.machine_learning.ml_utils.load_mish" href="#buteo.machine_learning.ml_utils.load_mish">load_mish</a></code></li>
<li><code><a title="buteo.machine_learning.ml_utils.log_cosh" href="#buteo.machine_learning.ml_utils.log_cosh">log_cosh</a></code></li>
<li><code><a title="buteo.machine_learning.ml_utils.mad_standard" href="#buteo.machine_learning.ml_utils.mad_standard">mad_standard</a></code></li>
<li><code><a title="buteo.machine_learning.ml_utils.mean_standard" href="#buteo.machine_learning.ml_utils.mean_standard">mean_standard</a></code></li>
<li><code><a title="buteo.machine_learning.ml_utils.min_max" href="#buteo.machine_learning.ml_utils.min_max">min_max</a></code></li>
<li><code><a title="buteo.machine_learning.ml_utils.minority_class_mask" href="#buteo.machine_learning.ml_utils.minority_class_mask">minority_class_mask</a></code></li>
<li><code><a title="buteo.machine_learning.ml_utils.mish" href="#buteo.machine_learning.ml_utils.mish">mish</a></code></li>
<li><code><a title="buteo.machine_learning.ml_utils.mse" href="#buteo.machine_learning.ml_utils.mse">mse</a></code></li>
<li><code><a title="buteo.machine_learning.ml_utils.mse_biased" href="#buteo.machine_learning.ml_utils.mse_biased">mse_biased</a></code></li>
<li><code><a title="buteo.machine_learning.ml_utils.mse_sumbias" href="#buteo.machine_learning.ml_utils.mse_sumbias">mse_sumbias</a></code></li>
<li><code><a title="buteo.machine_learning.ml_utils.pad" href="#buteo.machine_learning.ml_utils.pad">pad</a></code></li>
<li><code><a title="buteo.machine_learning.ml_utils.preprocess_coh" href="#buteo.machine_learning.ml_utils.preprocess_coh">preprocess_coh</a></code></li>
<li><code><a title="buteo.machine_learning.ml_utils.preprocess_optical" href="#buteo.machine_learning.ml_utils.preprocess_optical">preprocess_optical</a></code></li>
<li><code><a title="buteo.machine_learning.ml_utils.preprocess_sar" href="#buteo.machine_learning.ml_utils.preprocess_sar">preprocess_sar</a></code></li>
<li><code><a title="buteo.machine_learning.ml_utils.scale_percentile" href="#buteo.machine_learning.ml_utils.scale_percentile">scale_percentile</a></code></li>
<li><code><a title="buteo.machine_learning.ml_utils.scale_to_01" href="#buteo.machine_learning.ml_utils.scale_to_01">scale_to_01</a></code></li>
<li><code><a title="buteo.machine_learning.ml_utils.test_correlation" href="#buteo.machine_learning.ml_utils.test_correlation">test_correlation</a></code></li>
<li><code><a title="buteo.machine_learning.ml_utils.tpe" href="#buteo.machine_learning.ml_utils.tpe">tpe</a></code></li>
<li><code><a title="buteo.machine_learning.ml_utils.train_split_mask_regression" href="#buteo.machine_learning.ml_utils.train_split_mask_regression">train_split_mask_regression</a></code></li>
<li><code><a title="buteo.machine_learning.ml_utils.trunc_scale" href="#buteo.machine_learning.ml_utils.trunc_scale">trunc_scale</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="buteo.machine_learning.ml_utils.Mish" href="#buteo.machine_learning.ml_utils.Mish">Mish</a></code></h4>
</li>
<li>
<h4><code><a title="buteo.machine_learning.ml_utils.SaveBestModel" href="#buteo.machine_learning.ml_utils.SaveBestModel">SaveBestModel</a></code></h4>
<ul class="">
<li><code><a title="buteo.machine_learning.ml_utils.SaveBestModel.on_epoch_end" href="#buteo.machine_learning.ml_utils.SaveBestModel.on_epoch_end">on_epoch_end</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>