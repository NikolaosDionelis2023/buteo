{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "green",
   "display_name": "green",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Generate imagery"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutions!\n",
    "# Order of images\n",
    "# b4, b4_tex, b8, b8_tex, bs_asc, bs_desc, coh_asc, coh_desc, nl\n",
    "# Order of truth\n",
    "# id, fid, muni_code, volume, area, people\n",
    "\n",
    "# Local path, change this.\n",
    "yellow_follow = 'C:/Users/caspe/Desktop/yellow/lib/'\n",
    "\n",
    "import sys; sys.path.append(yellow_follow) \n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import ml_utils\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Flatten, Conv3D, MaxPooling3D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"C:/Users/caspe/Desktop/Paper_2_StructuralVolume/\"\n",
    "\n",
    "rotation = True\n",
    "rotation_count = 4\n",
    "epochs = 50\n",
    "initial_learning_rate = 0.001\n",
    "end_learning_rate = 0.00001\n",
    "\n",
    "munis = {\n",
    "    \"Lemvig\": 665,\n",
    "    \"Silkeborg\": 740,\n",
    "    \"Aarhus\": 751,\n",
    "}\n",
    "\n",
    "images = np.load(folder + \"all_images.npy\")\n",
    "images_metadata = np.load(folder + \"images_ground_truth.npy\")\n",
    "truth = np.load(folder + \"structural_volume.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_muni_mask = (images_metadata[:, 2] == munis[\"Lemvig\"])\n",
    "train_muni_mask = (images_metadata[:, 2] != munis[\"Silkeborg\"])\n",
    "\n",
    "X_test = images[test_muni_mask]\n",
    "y_test = truth[test_muni_mask]\n",
    "\n",
    "zero_mask = (images_metadata[:, 3] > 0)[test_muni_mask]\n",
    "\n",
    "X_train = images[train_muni_mask]\n",
    "y_train = truth[train_muni_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [0, 2, 4, 5, 6, 7] # bsac_bsdc_s2\n",
    "layer_name = \"bsac_bsdc_s2\"\n",
    "\n",
    "# Selected layers\n",
    "X_train = X_train[:, layers]\n",
    "X_test = X_test[:, layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple balance dataset (Equal amount 0 to rest)\n",
    "frequency = ml_utils.count_freq(zero_mask)\n",
    "minority = frequency.min(axis=0)[1]\n",
    "balance_mask = ml_utils.minority_class_mask(zero_mask, minority)\n",
    "\n",
    "X_train = X_train[balance_mask]\n",
    "y_train = y_train[balance_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rotation is True:\n",
    "    X_train = ml_utils.add_rotations(X_train, axes=(2, 3), k=rotation_count)\n",
    "    y_train = ml_utils.add_rotations(y_train, axes=(1, 2), k=rotation_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the training dataset\n",
    "shuffle_mask = np.random.permutation(len(y_train))\n",
    "X_train = X_train[shuffle_mask]\n",
    "y_train = y_train[shuffle_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_time_based_decay(epoch):\n",
    "    return initial_learning_rate - (epoch * ((initial_learning_rate - end_learning_rate) / epochs))\n",
    "\n",
    "def define_optimizer():\n",
    "    return tfa.optimizers.Lookahead(\n",
    "        Adam(\n",
    "            learning_rate=initial_learning_rate,\n",
    "            name=\"Adam\",\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(shape, name):\n",
    "    drop = 0.2\n",
    "    model_input = Input(shape=shape, name=name)\n",
    "    model = Conv2D(64, kernel_size=3, padding='same', activation=tfa.activations.mish, kernel_initializer='he_uniform')(model_input)\n",
    "    model = Conv2D(64, kernel_size=3, padding='same', activation=tfa.activations.mish, kernel_initializer='he_uniform')(model_input)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Dropout(drop)(model)\n",
    "\n",
    "    model = MaxPooling2D(pool_size=(2, 2), padding='same', strides=(2, 2))(model)\n",
    "\n",
    "    model = Conv2D(96, kernel_size=3, padding='same', activation=tfa.activations.mish, kernel_initializer='he_uniform')(model)\n",
    "    model = BatchNormalization()(model)  \n",
    "    model = Dropout(drop)(model)\n",
    "\n",
    "    model = Conv2D(128, kernel_size=3, padding='same', activation=tfa.activations.mish, kernel_initializer='he_uniform')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Dropout(drop)(model)\n",
    "\n",
    "    model = conv2d_transpose(128, kernel_size=3, padding='same', strides=2, activation=tfa.activations.mish, kernel_initializer='he_uniform')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Dropout(drop)(model)\n",
    "\n",
    "    model = Conv2D(96, kernel_size=3, padding='same', activation=tfa.activations.mish, kernel_initializer='he_uniform')(model_input)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Dropout(drop)(model)\n",
    "\n",
    "    model = Conv2D(64, kernel_size=3, padding='same', activation=tfa.activations.mish, kernel_initializer='he_uniform')(model_input)\n",
    "    model = Conv2D(64, kernel_size=3, padding='same', activation=tfa.activations.mish, kernel_initializer='he_uniform')(model_input)\n",
    "\n",
    "    return Model(inputs=[model_input], outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=define_optimizer(),\n",
    "    loss=\"mean_absolute_error\",\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    batch_size=512,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[\n",
    "        LearningRateScheduler(lr_time_based_decay, verbose=1),\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=9,\n",
    "            min_delta=1,\n",
    "            restore_best_weights=True,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\")\n",
    "loss, mae = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(\"\")\n",
    "loss, z_mae = model.evaluate(X_test[zero_mask], y_test[zero_mask], verbose=2)\n",
    "print(\"\")"
   ]
  }
 ]
}