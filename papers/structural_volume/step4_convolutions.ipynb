{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "green",
   "display_name": "green",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Convolutions!\n",
    "### Order of images\n",
    "    b4, b4_tex, b8, b8_tex, bs_asc, bs_desc, coh_asc, coh_desc, nl\n",
    "\n",
    "### Order of truth\n",
    "    id, fid, muni_code, volume, area, people"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local path, change this.\n",
    "yellow_follow = 'C:/Users/caspe/Desktop/yellow/lib/'\n",
    "\n",
    "import sys; sys.path.append(yellow_follow) \n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import ml_utils\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D, Flatten, Conv3D, MaxPooling3D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "\n",
    "folder = \"C:/Users/caspe/Desktop/Paper_2_StructuralVolume/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "initial_learning_rate = 0.001\n",
    "end_learning_rate = 0.00001\n",
    "\n",
    "target_muni = [\n",
    "    665, # Lemvig\n",
    "    740, # Silkeborg\n",
    "    751, # Aarhus\n",
    "]\n",
    "target_muni = target_muni[0]\n",
    "\n",
    "target = [\n",
    "    3, # Volume\n",
    "    4, # Area\n",
    "    5, # People\n",
    "]\n",
    "target = target[0]\n",
    "\n",
    "rotation = True\n",
    "rotation_count = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load(folder + \"all_images.npy\")\n",
    "truth = np.load(folder + \"images_ground_truth.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select municipality\n",
    "test_muni_mask = (truth[:, 2] == target_muni)\n",
    "train_muni_mask = (truth[:, 2] != target_muni)\n",
    "\n",
    "X_test = images[test_muni_mask]\n",
    "y_test = truth[test_muni_mask]\n",
    "\n",
    "X_train = images[train_muni_mask]\n",
    "y_train = truth[train_muni_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_layers = [\n",
    "    # { \"name\": \"s2\", \"layers\": [0, 2] },\n",
    "    # { \"name\": \"bsa\", \"layers\": [4] },\n",
    "    # { \"name\": \"bsd\", \"layers\": [5] },\n",
    "    # { \"name\": \"bsa_bsd\", \"layers\": [4, 5] },\n",
    "    # { \"name\": \"bsac\", \"layers\": [4, 6] },\n",
    "    # { \"name\": \"bsdc\", \"layers\": [5, 7] },\n",
    "    # { \"name\": \"bsac_bsdc\", \"layers\": [4, 5, 6, 7] },\n",
    "    # { \"name\": \"bsac_s2\", \"layers\": [0, 2, 4, 6] },\n",
    "    # { \"name\": \"bsa_bsd_s2\", \"layers\": [0, 2, 4, 5 },\n",
    "    { \"name\": \"bsac_bsdc_s2\", \"layers\": [0, 2, 4, 5, 6, 7] },\n",
    "]\n",
    "\n",
    "layers = all_layers[0][\"layers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected layers\n",
    "X_train = X_train[:, layers]\n",
    "y_train = y_train[:, target]\n",
    "\n",
    "X_test = X_test[:, layers]\n",
    "y_test = y_test[:, target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple balance dataset (Equal amount 0 to rest)\n",
    "balance_target = y_train > 0\n",
    "frequency = ml_utils.count_freq(balance_target)\n",
    "minority = frequency.min(axis=0)[1]\n",
    "balance_mask = ml_utils.minority_class_mask(balance_target, minority)\n",
    "\n",
    "X_train = X_train[balance_mask]\n",
    "y_train = y_train[balance_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_mask_sub = ml_utils.create_submask(y_train, 100000)\n",
    "# X_train = X_train[train_mask_sub]\n",
    "# y_train = y_train[train_mask_sub]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rotation is True:\n",
    "    X_train = ml_utils.add_rotations(X_train, axes=(2,3), k=rotation_count)\n",
    "    y_train = np.concatenate([y_train] * rotation_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the training dataset\n",
    "shuffle_mask = np.random.permutation(len(y_train))\n",
    "X_train = X_train[shuffle_mask]\n",
    "y_train = y_train[shuffle_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_time_based_decay(epoch):\n",
    "    return initial_learning_rate - (epoch * ((initial_learning_rate - end_learning_rate) / epochs))\n",
    "\n",
    "def define_optimizer():\n",
    "    return tfa.optimizers.Lookahead(\n",
    "        Adam(\n",
    "            learning_rate=initial_learning_rate,\n",
    "            name=\"Adam\",\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(shape, name):\n",
    "    drop = 0.25\n",
    "    model_input = Input(shape=shape, name=name)\n",
    "    model = Conv2D(64, kernel_size=3, padding='same', activation=tfa.activations.mish, kernel_initializer='he_uniform')(model_input)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Conv2D(64, kernel_size=3, padding='same', activation=tfa.activations.mish, kernel_initializer='he_uniform')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Dropout(drop)(model)\n",
    "\n",
    "    model = MaxPooling2D(pool_size=(2, 2))(model)\n",
    "\n",
    "    model = Conv2D(96, kernel_size=3, padding='same', activation=tfa.activations.mish, kernel_initializer='he_uniform')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Conv2D(96, kernel_size=3, padding='same', activation=tfa.activations.mish, kernel_initializer='he_uniform')(model)\n",
    "    model = BatchNormalization()(model)  \n",
    "    model = Dropout(drop)(model)\n",
    "\n",
    "    model = MaxPooling2D(pool_size=(2, 2))(model)\n",
    "\n",
    "    model = Conv2D(128, kernel_size=2, padding='same', activation=tfa.activations.mish, kernel_initializer='he_uniform')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Conv2D(128, kernel_size=2, padding='same', activation=tfa.activations.mish, kernel_initializer='he_uniform')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Dropout(drop)(model)\n",
    "\n",
    "    model = Flatten()(model)\n",
    "\n",
    "    model = Dense(256, activation=tfa.activations.mish, kernel_initializer='he_uniform')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Dense(128, activation=tfa.activations.mish, kernel_initializer='he_uniform')(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Dropout(drop)(model)\n",
    "\n",
    "    predictions = Dense(1, activation='relu')(model)\n",
    "\n",
    "    return Model(inputs=[model_input], outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = define_model(ml_utils.get_shape(X_train), \"conv2\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=define_optimizer(),\n",
    "    loss=\"mean_absolute_error\",\n",
    "    metrics=[\n",
    "        \"mean_absolute_error\",\n",
    "        # \"mean_absolute_percentage_error\",\n",
    "        # ml_utils.median_absolute_error,\n",
    "        # ml_utils.median_absolute_percentage_error,\n",
    "    ])\n",
    "\n",
    "model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train, # area\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    batch_size=384,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[\n",
    "        LearningRateScheduler(lr_time_based_decay, verbose=1),\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=9,\n",
    "            min_delta=1,\n",
    "            restore_best_weights=True,\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_mask = y_test > 0\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\")\n",
    "loss, mae = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(\"\")\n",
    "loss, z_mae = model.evaluate(X_test[zero_mask], y_test[zero_mask], verbose=2)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/cnn_lemvig.h5', include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = truth[test_muni_mask]\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.DataFrame(truth[test_muni_mask], columns=[[\"id\", \"fid\", \"muni_code\", \"volume\", \"area\", \"people\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[\"cnn_pred_vol_lemvig\"] = pred\n",
    "\n",
    "engine = create_engine(f\"sqlite:///./predictions/cnn_pred_vol_lemvig.sqlite\", echo=True)\n",
    "sqlite_connection = engine.connect()\n",
    "\n",
    "y_test.to_sql(\"cnn_pred_vol_lemvig\", sqlite_connection, if_exists='fail')\n",
    "sqlite_connection.close()"
   ]
  }
 ]
}