{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "green",
   "display_name": "green",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Summary Statistics Approach"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local path, change this.\n",
    "yellow_follow = 'C:/Users/caspe/Desktop/yellow/lib/'\n",
    "\n",
    "import sys; sys.path.append(yellow_follow) \n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import ml_utils\n",
    "import numpy as np\n",
    "\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import Huber, MSLE\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "source": [
    "# Load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "folder = \"C:/Users/caspe/Desktop/Paper_2_StructuralVolume/\"\n",
    "in_path = folder + \"grid.sqlite\"\n",
    "\n",
    "db_cnx = sqlite3.connect(in_path)\n",
    "df = pd.read_sql_query(\"SELECT * FROM 'grid';\", db_cnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Easy reference to the different features in the datasets.\n",
    "s2 = [\n",
    "    'b04_mean', 'b04_stdev', 'b04_min', 'b04_max',\n",
    "    'b08_mean', 'b08_stdev', 'b08_min', 'b08_max',\n",
    "    'b04t_mean', 'b04t_stdev', 'b04t_min', 'b04t_max',\n",
    "    'b08t_mean', 'b08t_stdev', 'b08t_min', 'b08t_max',\n",
    "]\n",
    "\n",
    "bs_asc = ['bs_asc_mean', 'bs_asc_stdev', 'bs_asc_min', 'bs_asc_max']\n",
    "bs_desc = ['bs_desc_mean', 'bs_desc_stdev', 'bs_desc_min', 'bs_desc_max']\n",
    "coh_asc = ['coh_asc_mean', 'coh_asc_stdev', 'coh_asc_min', 'coh_asc_max']\n",
    "coh_desc = ['coh_desc_mean', 'coh_desc_stdev', 'coh_desc_min', 'coh_desc_max']\n",
    "\n",
    "nl = ['nl_mean', 'nl_stdev', 'nl_min', 'nl_max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The municipalities used as test targets\n",
    "#                       Rural,                  Mix,    Dense-urban\n",
    "test_municipalities = ['Lemvig', 'Silkeborg', 'Aarhus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'volume'\n",
    "# target = 'people'\n",
    "# target = 'area'"
   ]
  },
  {
   "source": [
    "# Define the neural network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "def define_model(shape, name):\n",
    "    model_input = Input(shape=shape, name=\"input\")\n",
    "    model = Dense(1024, activation=tfa.activations.mish, kernel_initializer=\"he_normal\")(model_input)\n",
    "    model = Dropout(0.2)(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Dense(256, activation=tfa.activations.mish, kernel_initializer=\"he_normal\")(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Dense(64, activation=tfa.activations.mish, kernel_initializer=\"he_normal\")(model)\n",
    "    model = Dense(16, activation=tfa.activations.mish, kernel_initializer=\"he_normal\")(model)\n",
    "\n",
    "    predictions = Dense(1, activation='relu')(model)\n",
    "\n",
    "    return Model(inputs=[model_input], outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Optimizer\n",
    "def define_optimizer():\n",
    "    return tfa.optimizers.Lookahead(\n",
    "        Adam(\n",
    "            learning_rate=tfa.optimizers.TriangularCyclicalLearningRate(\n",
    "                initial_learning_rate=1e-5,\n",
    "                maximal_learning_rate=1e-2,\n",
    "                step_size=9,\n",
    "                scale_mode='cycle',\n",
    "                name='TriangularCyclicalLearningRate',\n",
    "            ),\n",
    "            name=\"Adam\",\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "source": [
    "# Start analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_to_run = [\n",
    "    # nl,\n",
    "    # s2,\n",
    "    # bs_asc,\n",
    "    # bs_desc,\n",
    "    # bs_asc + bs_desc, \n",
    "    # bs_asc + coh_asc,\n",
    "    # bs_desc + coh_desc,\n",
    "    # bs_asc + coh_asc + s2,\n",
    "    # bs_asc + coh_asc + bs_desc + coh_desc,\n",
    "    bs_asc + coh_asc + bs_desc + coh_desc + s2,\n",
    "    # bs_asc + coh_asc + bs_desc + coh_desc + s2 + nl,\n",
    "]\n",
    "analysis_name = 'bsac_bsdc_s2'"
   ]
  },
  {
   "source": [
    "# Train and evaluate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "all_analysis = []\n",
    "\n",
    "for idx, analysis in enumerate(analysis_to_run):\n",
    "\n",
    "    scores = { \"analysis\": str(analysis) }\n",
    "\n",
    "    for muni in test_municipalities:\n",
    "        train = df[df['muni_name'] != muni]\n",
    "        test = df[df['muni_name'] == muni]\n",
    "\n",
    "        muni_code = str(int(test['muni_code'].iloc[0]))\n",
    "        \n",
    "        X_train = train[analysis].values\n",
    "        X_test = test[analysis].values\n",
    "\n",
    "        y_train = train[target].values\n",
    "        y_test = test[target].values\n",
    "\n",
    "        shape = X_train.shape[1]\n",
    "        model = define_model(shape, \"input\")\n",
    "\n",
    "        # Compile and test model\n",
    "        model.compile(\n",
    "            optimizer=define_optimizer(),\n",
    "            loss=\"mean_absolute_error\",\n",
    "            metrics=[\n",
    "                \"mean_absolute_error\",\n",
    "                \"mean_absolute_percentage_error\",\n",
    "                ml_utils.median_absolute_error,\n",
    "                ml_utils.median_absolute_percentage_error,\n",
    "            ])\n",
    "\n",
    "        model.fit(\n",
    "            x=X_train,\n",
    "            y=y_train,\n",
    "            epochs=100,\n",
    "            verbose=1,\n",
    "            batch_size=2048,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[\n",
    "                EarlyStopping(\n",
    "                    monitor=\"val_loss\",\n",
    "                    patience=9,\n",
    "                    min_delta=5.0,\n",
    "                    restore_best_weights=True,\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Evaluate model\n",
    "        loss, mae, mape, meae, meape = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "        scores[muni] = {\n",
    "            \"mean_absolute_error\": mae,\n",
    "            \"mean_absolute_percentage_error\": mape,\n",
    "            \"median_absolute_error\": meae,\n",
    "            \"median_absolute_percentage_error\": meape,\n",
    "        }\n",
    "\n",
    "        # Save the predicted values\n",
    "        pred = model.predict(X_test)\n",
    "        test[f\"pred_{analysis_name}_{muni_code}\"] = pred\n",
    "\n",
    "        engine = create_engine(f\"sqlite:///{folder}grid_{analysis_name}_{muni_code}.sqlite\", echo=True)\n",
    "        sqlite_connection = engine.connect()\n",
    "\n",
    "        test.to_sql(f\"grid_{analysis_name}_{muni_code}\", sqlite_connection, if_exists='fail')\n",
    "        sqlite_connection.close()\n",
    "\n",
    "\n",
    "    all_analysis.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, analysis in enumerate(all_analysis):\n",
    "    print(f\"Analysis: {analysis_name}\")\n",
    "    print(\"\")\n",
    "\n",
    "    combined = {\n",
    "        \"MAE\": [],\n",
    "        \"MAPE\": [],\n",
    "        \"MeAE\": [],\n",
    "        \"MeAPE\": [],\n",
    "    }\n",
    "\n",
    "    for munipality in test_municipalities:\n",
    "        test_area_name = munipality\n",
    "        test_data = analysis[test_area_name]\n",
    "\n",
    "        mean_absolute_error = test_data[\"mean_absolute_error\"]\n",
    "        mean_absolute_percentage_error = test_data[\"mean_absolute_percentage_error\"]\n",
    "        median_absolute_error = test_data[\"median_absolute_error\"]\n",
    "        median_absolute_percentage_error = test_data[\"median_absolute_percentage_error\"]\n",
    "\n",
    "        combined[\"MAE\"].append(mean_absolute_error)\n",
    "        combined[\"MAPE\"].append(mean_absolute_percentage_error)\n",
    "        combined[\"MeAE\"].append(median_absolute_error)\n",
    "        combined[\"MeAPE\"].append(median_absolute_percentage_error)\n",
    "\n",
    "        print(f\"    Test area: {test_area_name}\")\n",
    "        print(f\"    Mean Absolute Error (MAE):                {ml_utils.pad(str(round(mean_absolute_error, 3)), 5, 3)}\")\n",
    "        print(f\"    Mean Absolute Percentage Error (MAPE):    {ml_utils.pad(str(round(mean_absolute_percentage_error * 100, 3)), 5, 3)}\")\n",
    "        print(f\"    Median Absolute Error (MeAE):             {ml_utils.pad(str(round(median_absolute_error, 3)), 5, 3)}\")\n",
    "        print(f\"    Median Absolute Percentage Error (MeAPE): {ml_utils.pad(str(round(median_absolute_percentage_error * 100, 3)), 5, 3)}\")\n",
    "        print(\"\")\n",
    "    \n",
    "    mae_mean = np.array(combined['MAE']).mean()\n",
    "    mae_std = np.array(combined['MAE']).std()\n",
    "\n",
    "    mape_mean = np.array(combined['MAPE']).mean()\n",
    "    mape_std = np.array(combined['MAPE']).std()\n",
    "\n",
    "    meae_mean = np.array(combined['MeAE']).mean()\n",
    "    meae_std = np.array(combined['MeAE']).std()\n",
    "\n",
    "    meape_mean = np.array(combined['MeAPE']).mean()\n",
    "    meapee_std = np.array(combined['MeAPE']).std()\n",
    "\n",
    "\n",
    "    print(f\"    Combined Score:\")\n",
    "    print(f\"    Mean Absolute Error (MAE):               {ml_utils.pad(str(round(mae_mean, 3)), 5, 3)} ({ml_utils.pad(str(round(mae_mean, 3)), 5, 3)} σ)\")\n",
    "    print(f\"    Mean Absolute Percentage Error (MAPE):   {ml_utils.pad(str(round(mape_mean * 100, 3)), 5, 3)} ({ml_utils.pad(str(round(mape_std * 100, 3)), 5, 3)} σ)\")\n",
    "    print(f\"    Median Absolute Error (MeAE):            {ml_utils.pad(str(round(meae_mean, 3)), 5, 3)} ({ml_utils.pad(str(round(meae_std, 3)), 5, 3)} σ)\")\n",
    "    print(f\"    Median Absolute Percentage Error (MAPE): {ml_utils.pad(str(round(meape_mean * 100, 3)), 5, 3)} ({ml_utils.pad(str(round(meapee_std * 100, 3)), 5, 3)} σ)\")\n",
    "    print(\"\")"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}